{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Computes Mel-frequencies and deltas\n",
    "- Computes MFCC and deltas\n",
    "- Creates train and test sets for both Mel and MFCC features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# import librosa.display\n",
    "# from matplotlib import pyplot as plt\n",
    "\n",
    "# import IPython.display as ipd\n",
    "# import os, audioread, re\n",
    "# from matplotlib.pyplot import specgram\n",
    "\n",
    "# import pandas as pd\n",
    "# import random as rndm\n",
    "# from random import shuffle\n",
    "import glob, audioread\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scipy/linalg/basic.py:1226: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  warnings.warn(mesg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "def load_and_read_data(files_path, sr=16000): \n",
    "    audio=[]\n",
    "    sample_rates=[]\n",
    "    channels=[]\n",
    "    \n",
    "    # get all wav files in folder\n",
    "    sound_file_paths = glob.glob(files_path + '*.wav')\n",
    "    \n",
    "    #iterate over files and extract features.\n",
    "    for file in sound_file_paths:\n",
    "        ts, sr = librosa.load(file,sr=sr) #librosa returns a time series and sample rate\n",
    "        audio.append(ts)\n",
    "        sample_rates.append(sr)  \n",
    "        with audioread.audio_open(file) as input_file:\n",
    "            channels.append(input_file.channels)\n",
    "            \n",
    "    return audio, sample_rates, channels, sound_file_paths\n",
    "    \n",
    "def get_more_audio_features(audio, sr=16000):\n",
    "    frequencies = []    \n",
    "    mel_deltas = []\n",
    "    mfccs = []\n",
    "    mfcc_deltas = []\n",
    "    \n",
    "    for a in audio:\n",
    "        # Get and store frequencies and their deltas\n",
    "        fr = librosa.feature.melspectrogram(y=a,sr=sr)\n",
    "        frequencies.append(fr)\n",
    "        mel_deltas.append(librosa.feature.delta(fr))\n",
    "        \n",
    "        # Get and store mfccs and their deltas        \n",
    "        mfcc = librosa.feature.mfcc(S=librosa.power_to_db(fr),sr=sr)\n",
    "        mfccs.append(mfcc)\n",
    "        mfcc_deltas.append(librosa.feature.delta(mfcc))\n",
    "\n",
    "    return frequencies, mel_deltas, mfccs, mfcc_deltas\n",
    "\n",
    "#path for audio files folder:\n",
    "raw_files_path = 'data/cats_dogs/'\n",
    "\n",
    "#call the function that will process the data.\n",
    "audio, sr, channels, file_names = load_and_read_data(raw_files_path)    \n",
    "\n",
    "#get additional features from audio\n",
    "frequencies, mel_deltas, mfccs, mfcc_deltas = get_more_audio_features(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.transpose(frequencies[0])[0]\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_features_dataframe1(features_name, features_cats, features_dogs, files_id, removeSilentFrames=False, labelSilentFrames=False):\n",
    "        \n",
    "    df=pd.DataFrame()\n",
    "    for index, item in enumerate(features_name):\n",
    "        \n",
    "        df_filec=pd.DataFrame([[np.transpose(item)[0]]])        \n",
    "        for frame_mels in range(1,np.transpose(features_name).shape[0]):\n",
    "            df_filec=df_filec.append([[np.transpose(item)[frame_mels]]], ignore_index= True)\n",
    "        df_filec['file_id']=file_names[index]\n",
    "        df=df_cats.append(df_filec)    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# GENERIC DATAFRAME that accepts any size features:\n",
    "#features_name='mel', 'mel_delta', 'mfccs', 'mfcc_delta'\n",
    "#features_cats is a list with the features extracted for each file.\n",
    "def build_features_Dataframe(features_name, features_cats, features_dogs, files_id, removeSilentFrames=False, labelSilentFrames=False):\n",
    "        \n",
    "    df_cats=pd.DataFrame()\n",
    "    for f in range(0, len(features_cats)):\n",
    "        df_filec=pd.DataFrame([[np.transpose(features_cats[f])[0]]])\n",
    "        for frame_mels in range(1,np.transpose(features_cats[f]).shape[0]):\n",
    "            df_filec=df_filec.append([[np.transpose(features_cats[f])[frame_mels]]], ignore_index= True)\n",
    "   \n",
    "        df_filec['file_id']=files_id[f]\n",
    "        df_cats=df_cats.append(df_filec)    \n",
    "\n",
    "    df_cats['label']=catLabel\n",
    "    df_cats.columns = [features_name, 'File_id', 'Label']\n",
    "\n",
    "    df_dogs=pd.DataFrame()\n",
    "    for fd in range(0, len(features_dogs)):\n",
    "        df_file=pd.DataFrame([[np.transpose(features_dogs[fd])[0]]])\n",
    "        for frame_mels in range(1,np.transpose(features_dogs[fd]).shape[0]):\n",
    "            df_file=df_file.append([[np.transpose(features_dogs[fd])[frame_mels]]], ignore_index= True)\n",
    "\n",
    "        df_file['file_id']=files_id[fd+n_cats]\n",
    "        df_dogs=df_dogs.append(df_file)    \n",
    "\n",
    "    df_dogs['label']=dogLabel\n",
    "    df_dogs.columns = [features_name, 'File_id', 'Label']\n",
    "    return df_cats, df_dogs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def split_dataframes(cats_dataframe,dogs_dataframe,test_size=0.3):\n",
    "\n",
    "    #keep unbalanced dataset in the training for now: 0.7*164 cats+ 0.7*113 dogs\n",
    "    n_train_files_cats=(int((1-test_size)*n_cats))\n",
    "    n_train_files_dogs=(int((1-test_size)*n_dogs))\n",
    "    \n",
    "    # select 30% as test and 70% as train at file level! \n",
    "    files_id_cats=files_id[0:n_cats]\n",
    "    files_id_dogs=files_id[n_cats:n_cats+n_dogs]\n",
    "    rndm.shuffle(files_id_cats)\n",
    "\n",
    "    files_id_cats_train=[]\n",
    "    files_id_cats_test=[]\n",
    "    for i in range(0,n_train_files_cats):\n",
    "        files_id_cats_train.append(files_id_cats[i])\n",
    "    files_id_cats_test=files_id_cats[n_train_files_cats:]\n",
    "\n",
    "    \n",
    "    rndm.shuffle(files_id_dogs)    \n",
    "    files_id_dogs_train=[]\n",
    "    files_id_dogs_test=[]\n",
    "    for i in range(0,n_train_files_dogs):\n",
    "        files_id_dogs_train.append(files_id_dogs[i])\n",
    "    files_id_dogs_test=files_id_dogs[n_train_files_dogs:]\n",
    "\n",
    "    dftrain_cats=cats_dataframe.loc[cats_dataframe['File_id'].isin(files_id_cats_train)]\n",
    "    dftest_cats=cats_dataframe.loc[cats_dataframe['File_id'].isin(files_id_cats_test)]\n",
    "    dftrain_dogs=dogs_dataframe.loc[dogs_dataframe['File_id'].isin(files_id_dogs_train)]\n",
    "    dftest_dogs=dogs_dataframe.loc[dogs_dataframe['File_id'].isin(files_id_dogs_test)]\n",
    "\n",
    "    # concatenate in two dataframe test and train.\n",
    "    df_TRAIN=pd.DataFrame()\n",
    "    df_TEST=pd.DataFrame()\n",
    "    df_TRAIN=df_TRAIN.append(dftrain_cats)\n",
    "    df_TRAIN=df_TRAIN.append(dftrain_dogs)\n",
    "    df_TEST=df_TEST.append(dftest_cats)\n",
    "    df_TEST=df_TEST.append(dftest_dogs)\n",
    "\n",
    "\n",
    "    # # shuffle...\n",
    "    df_TEST=df_TEST.sample(frac=1)\n",
    "    df_TRAIN=df_TRAIN.sample(frac=1)\n",
    "    return df_TRAIN, df_TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the files:\n",
    "Cats_audio, cats_sr, channel_cats, Dogs_audio, dogs_sr, channel_dogs= load_data( sound_file_paths, sr=None)\n",
    "sr=16000\n",
    "#Feature computation\n",
    "\n",
    "cats_mel_frequencies,dogs_mel_frequencies=compute_mel_frequencies(Cats_audio,Dogs_audio , sr)\n",
    "cats_mel_deltas, dogs_mel_deltas=compute_MEL_deltas(cats_mel_frequencies,dogs_mel_frequencies)\n",
    "cats_mfccs, dogs_mfccs= compute_mfccs(cats_mel_frequencies,dogs_mel_frequencies,sr)\n",
    "cats_mfcc_delta, dogs_mfcc_delta=compute_MFCC_deltas(cats_mfccs,dogs_mfccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Features Dataframes per class:\n",
    "\n",
    "df_cats_melDeltas, df_dogs_melDeltas =build_features_Dataframe('Mel_deltas',cats_mel_deltas, dogs_mel_deltas, files_id )\n",
    "df_cats_mel, df_dogs_mel =build_features_Dataframe('Mel',cats_mel_frequencies, dogs_mel_frequencies, files_id )\n",
    "df_cats_MFCCDeltas, df_dogs_MFCCDeltas =build_features_Dataframe('MFCC_deltas',cats_mfcc_delta, dogs_mfcc_delta, files_id )\n",
    "df_cats_MFCC, df_dogs_MFCC =build_features_Dataframe('MFCC',cats_mfccs, dogs_mfccs, files_id )\n",
    "\n",
    "\n",
    "# Features concatenation dataframes:\n",
    "df_cats_melANDdeltas=pd.DataFrame()\n",
    "df_cats_MFCC_AND_Deltas=pd.DataFrame()\n",
    "df_dogs_melANDdeltas=pd.DataFrame()\n",
    "df_dogs_MFCC_AND_Deltas=pd.DataFrame()\n",
    "\n",
    "df_cats_melANDdeltas=pd.concat([df_cats_mel, df_cats_melDeltas['Mel_deltas']], axis=1 )\n",
    "df_cats_MFCC_AND_Deltas = pd.concat([df_cats_MFCC, df_cats_MFCCDeltas['MFCC_deltas']] , axis=1 )\n",
    "df_dogs_melANDdeltas = pd.concat([df_dogs_mel, df_dogs_melDeltas['Mel_deltas']] , axis=1)\n",
    "df_dogs_MFCC_AND_Deltas = pd.concat([df_dogs_MFCC, df_dogs_MFCCDeltas['MFCC_deltas']],axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates Test and Train Sets and saves the dataframes:\n",
    "\n",
    "df_TRAIN_final=pd.DataFrame() \n",
    "df_TEST_final=pd.DataFrame() \n",
    "df_TRAIN_final, df_TEST_final = split_dataframes( df_cats_melANDdeltas, df_dogs_melANDdeltas, test_size=0.3)\n",
    "df_TRAIN_final.to_pickle('.\\Features_sets/'+ 'Train_MELandDeltas.pkl')  \n",
    "df_TEST_final.to_pickle('.\\Features_sets/'+ 'Test_MELandDeltas.pkl')\n",
    "\n",
    "\n",
    "df_TRAIN_final=pd.DataFrame() \n",
    "df_TEST_final=pd.DataFrame() \n",
    "df_TRAIN_final, df_TEST_final = split_dataframes( df_cats_MFCC_AND_Deltas, df_dogs_MFCC_AND_Deltas, test_size=0.3)\n",
    "df_TRAIN_final.to_pickle('.\\Features_sets/'+ 'Train_MFCCandDeltas.pkl')  \n",
    "df_TEST_final.to_pickle('.\\Features_sets/'+ 'Test_MFCCandDeltas.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
