{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Computes Mel-frequencies and deltas\n",
    "- Computes MFCC and deltas\n",
    "- Creates train and test sets for both Mel and MFCC features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "from matplotlib import pyplot as plt\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import os\n",
    "import audioread\n",
    "from matplotlib.pyplot import specgram\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import random as rndm\n",
    "from random import shuffle\n",
    "\n",
    "#path for audio files folder:\n",
    "relevant_path = './data/cats_dogs/'\n",
    "\n",
    "# get files from directory and do all or a few, depending on range extracted below\n",
    "sound_file_paths = [relevant_path+f for f in os.listdir(relevant_path)]\n",
    "\n",
    "files_id=[]\n",
    "pattern='(\\w*_\\d*).wav'\n",
    "for n in sound_file_paths:\n",
    "    files_id.append(re.search(pattern, n ).group(1))\n",
    "\n",
    "\n",
    "#print(files_id)\n",
    "n_cats=164 # number of files with cat sounds\n",
    "n_dogs=113 # number of files with barking sounds    \n",
    "catLabel=0\n",
    "dogLabel=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_data( files_path, sr=None): \n",
    "        \n",
    "    cats = []\n",
    "    cats_sr=[]\n",
    "    channel_cats = []\n",
    "    dogs = []\n",
    "    channel_dogs = []\n",
    "    dogs_sr=[]\n",
    "   \n",
    "    for i in range(n_cats):\n",
    "       # print(files_path[i])\n",
    "        cat_i, sr_i = librosa.load(files_path[i],sr=sr)\n",
    "        cats.append(cat_i)\n",
    "        cats_sr.append(sr_i)\n",
    "        with audioread.audio_open(files_path[i]) as input_file:\n",
    "            channel_cats.append(input_file.channels)\n",
    "   \n",
    "    for j in range(n_cats, n_cats + n_dogs):\n",
    "       # print(files_path[j])\n",
    "        dog_j, sr_j = librosa.load(files_path[j],sr=sr)\n",
    "        dogs.append(dog_j)\n",
    "        dogs_sr.append(sr_j)\n",
    "        with audioread.audio_open(files_path[j]) as input_file:\n",
    "            channel_dogs.append(input_file.channels)\n",
    "\n",
    "    #channel_cats = list(channel_cats)\n",
    "    #channel_dogs = list(channel_dogs)\n",
    "    \n",
    "    return cats, cats_sr, channel_cats, dogs, dogs_sr, channel_dogs\n",
    "\n",
    "\n",
    "#Feature extraction and dataframe manipulation functions:\n",
    "\n",
    "\n",
    "# extract mel_spectograms:\n",
    "# Compute_mel_frequencies function:\n",
    "# Computes the Mel-scaled spectrograms for each audio file\n",
    "# input: lists of raw audio for cats and dogs, and sampling rate\n",
    "#output: melspectograms for each file, in a list per class\n",
    "def compute_mel_frequencies(cats,dogs, sr ):\n",
    "    cats_mel_frequencies = []\n",
    "    dogs_mel_frequencies = []\n",
    "    \n",
    "    for c in cats:\n",
    "        cats_mel_frequencies.append(librosa.feature.melspectrogram(y=c,sr=sr))\n",
    "    for d in dogs:\n",
    "        dogs_mel_frequencies.append(librosa.feature.melspectrogram(y=d,sr=sr))\n",
    "        \n",
    "    return cats_mel_frequencies,dogs_mel_frequencies\n",
    "\n",
    "def compute_MEL_deltas(cats_mel_frequencies,dogs_mel_frequencies):\n",
    "    cats_mel_deltas = []\n",
    "    dogs_dogs_deltas = []\n",
    "    \n",
    "    for i in range(164):\n",
    "        cats_mel_deltas.append(librosa.feature.delta(cats_mel_frequencies[i]))\n",
    "    for i in range(113):\n",
    "        dogs_dogs_deltas.append(librosa.feature.delta(dogs_mel_frequencies[i]))\n",
    "   \n",
    "    return cats_mel_deltas, dogs_dogs_deltas\n",
    "\n",
    "# extract MFCCs:\n",
    "def compute_mfccs(cats_mel_frequencies,dogs_mel_frequencies,sr=22050):\n",
    "    cats_mfccs = []\n",
    "    dogs_mfccs = []\n",
    "    \n",
    "    for i in range(n_cats):\n",
    "        cats_mfccs.append(librosa.feature.mfcc(S=librosa.power_to_db(cats_mel_frequencies[i]),sr=sr))\n",
    "    for i in range(n_dogs):\n",
    "        dogs_mfccs.append(librosa.feature.mfcc(S=librosa.power_to_db(dogs_mel_frequencies[i]),sr=sr))\n",
    "        \n",
    "    return cats_mfccs,dogs_mfccs\n",
    "\n",
    "def compute_MFCC_deltas(cats_mfccs,dogs_mfccs):\n",
    "    cats_deltas = []\n",
    "    dogs_deltas = []\n",
    "    \n",
    "    for i in range(164):\n",
    "        cats_deltas.append(librosa.feature.delta(cats_mfccs[i]))\n",
    "    for i in range(113):\n",
    "        dogs_deltas.append(librosa.feature.delta(dogs_mfccs[i]))\n",
    "        \n",
    "    return cats_deltas,dogs_deltas\n",
    "\n",
    "\n",
    "\n",
    "#to access a specific cell > dataframe.iloc[row]['column?name']\n",
    "\n",
    "\n",
    "# GENERIC DATAFRAME that accepts any size features:\n",
    "#features_name='mel', 'mel_delta', 'mfccs', 'mfcc_delta'\n",
    "#features_cats is a list with the features extracted for each file.\n",
    "def build_features_Dataframe(features_name, features_cats, features_dogs, files_id, removeSilentFrames=False, labelSilentFrames=False):\n",
    "        \n",
    "    df_cats=pd.DataFrame()\n",
    "    for f in range(0, len(features_cats)):\n",
    "        df_filec=pd.DataFrame([[np.transpose(features_cats[f])[0]]])\n",
    "        for frame_mels in range(1,np.transpose(features_cats[f]).shape[0]):\n",
    "            df_filec=df_filec.append([[np.transpose(features_cats[f])[frame_mels]]], ignore_index= True)\n",
    "   \n",
    "        df_filec['file_id']=files_id[f]\n",
    "        df_cats=df_cats.append(df_filec)    \n",
    "\n",
    "    df_cats['label']=catLabel\n",
    "    df_cats.columns = [features_name, 'File_id', 'Label']\n",
    "\n",
    "    df_dogs=pd.DataFrame()\n",
    "    for fd in range(0, len(features_dogs)):\n",
    "        df_file=pd.DataFrame([[np.transpose(features_dogs[fd])[0]]])\n",
    "        for frame_mels in range(1,np.transpose(features_dogs[fd]).shape[0]):\n",
    "            df_file=df_file.append([[np.transpose(features_dogs[fd])[frame_mels]]], ignore_index= True)\n",
    "\n",
    "        df_file['file_id']=files_id[fd+n_cats]\n",
    "        df_dogs=df_dogs.append(df_file)    \n",
    "\n",
    "    df_dogs['label']=dogLabel\n",
    "    df_dogs.columns = [features_name, 'File_id', 'Label']\n",
    "    return df_cats, df_dogs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def split_dataframes(cats_dataframe,dogs_dataframe,test_size=0.3):\n",
    "\n",
    "    #keep unbalanced dataset in the training for now: 0.7*164 cats+ 0.7*113 dogs\n",
    "    n_train_files_cats=(int((1-test_size)*n_cats))\n",
    "    n_train_files_dogs=(int((1-test_size)*n_dogs))\n",
    "    \n",
    "    # select 30% as test and 70% as train at file level! \n",
    "    files_id_cats=files_id[0:n_cats]\n",
    "    files_id_dogs=files_id[n_cats:n_cats+n_dogs]\n",
    "    rndm.shuffle(files_id_cats)\n",
    "\n",
    "    files_id_cats_train=[]\n",
    "    files_id_cats_test=[]\n",
    "    for i in range(0,n_train_files_cats):\n",
    "        files_id_cats_train.append(files_id_cats[i])\n",
    "    files_id_cats_test=files_id_cats[n_train_files_cats:]\n",
    "\n",
    "    \n",
    "    rndm.shuffle(files_id_dogs)    \n",
    "    files_id_dogs_train=[]\n",
    "    files_id_dogs_test=[]\n",
    "    for i in range(0,n_train_files_dogs):\n",
    "        files_id_dogs_train.append(files_id_dogs[i])\n",
    "    files_id_dogs_test=files_id_dogs[n_train_files_dogs:]\n",
    "\n",
    "    dftrain_cats=cats_dataframe.loc[cats_dataframe['File_id'].isin(files_id_cats_train)]\n",
    "    dftest_cats=cats_dataframe.loc[cats_dataframe['File_id'].isin(files_id_cats_test)]\n",
    "    dftrain_dogs=dogs_dataframe.loc[dogs_dataframe['File_id'].isin(files_id_dogs_train)]\n",
    "    dftest_dogs=dogs_dataframe.loc[dogs_dataframe['File_id'].isin(files_id_dogs_test)]\n",
    "\n",
    "    # concatenate in two dataframe test and train.\n",
    "    df_TRAIN=pd.DataFrame()\n",
    "    df_TEST=pd.DataFrame()\n",
    "    df_TRAIN=df_TRAIN.append(dftrain_cats)\n",
    "    df_TRAIN=df_TRAIN.append(dftrain_dogs)\n",
    "    df_TEST=df_TEST.append(dftest_cats)\n",
    "    df_TEST=df_TEST.append(dftest_dogs)\n",
    "\n",
    "\n",
    "    # # shuffle...\n",
    "    df_TEST=df_TEST.sample(frac=1)\n",
    "    df_TRAIN=df_TRAIN.sample(frac=1)\n",
    "    return df_TRAIN, df_TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the files:\n",
    "Cats_audio, cats_sr, channel_cats, Dogs_audio, dogs_sr, channel_dogs= load_data( sound_file_paths, sr=None)\n",
    "sr=16000\n",
    "#Feature computation\n",
    "\n",
    "cats_mel_frequencies,dogs_mel_frequencies=compute_mel_frequencies(Cats_audio,Dogs_audio , sr)\n",
    "cats_mel_deltas, dogs_mel_deltas=compute_MEL_deltas(cats_mel_frequencies,dogs_mel_frequencies)\n",
    "cats_mfccs, dogs_mfccs= compute_mfccs(cats_mel_frequencies,dogs_mel_frequencies,sr)\n",
    "cats_mfcc_delta, dogs_mfcc_delta=compute_MFCC_deltas(cats_mfccs,dogs_mfccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Features Dataframes per class:\n",
    "\n",
    "df_cats_melDeltas, df_dogs_melDeltas =build_features_Dataframe('Mel_deltas',cats_mel_deltas, dogs_mel_deltas, files_id )\n",
    "df_cats_mel, df_dogs_mel =build_features_Dataframe('Mel',cats_mel_frequencies, dogs_mel_frequencies, files_id )\n",
    "df_cats_MFCCDeltas, df_dogs_MFCCDeltas =build_features_Dataframe('MFCC_deltas',cats_mfcc_delta, dogs_mfcc_delta, files_id )\n",
    "df_cats_MFCC, df_dogs_MFCC =build_features_Dataframe('MFCC',cats_mfccs, dogs_mfccs, files_id )\n",
    "\n",
    "\n",
    "# Features concatenation dataframes:\n",
    "df_cats_melANDdeltas=pd.DataFrame()\n",
    "df_cats_MFCC_AND_Deltas=pd.DataFrame()\n",
    "df_dogs_melANDdeltas=pd.DataFrame()\n",
    "df_dogs_MFCC_AND_Deltas=pd.DataFrame()\n",
    "\n",
    "df_cats_melANDdeltas=pd.concat([df_cats_mel, df_cats_melDeltas['Mel_deltas']], axis=1 )\n",
    "df_cats_MFCC_AND_Deltas = pd.concat([df_cats_MFCC, df_cats_MFCCDeltas['MFCC_deltas']] , axis=1 )\n",
    "df_dogs_melANDdeltas = pd.concat([df_dogs_mel, df_dogs_melDeltas['Mel_deltas']] , axis=1)\n",
    "df_dogs_MFCC_AND_Deltas = pd.concat([df_dogs_MFCC, df_dogs_MFCCDeltas['MFCC_deltas']],axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates Test and Train Sets and saves the dataframes:\n",
    "\n",
    "df_TRAIN_final=pd.DataFrame() \n",
    "df_TEST_final=pd.DataFrame() \n",
    "df_TRAIN_final, df_TEST_final = split_dataframes( df_cats_melANDdeltas, df_dogs_melANDdeltas, test_size=0.3)\n",
    "df_TRAIN_final.to_pickle('.\\Features_sets/'+ 'Train_MELandDeltas.pkl')  \n",
    "df_TEST_final.to_pickle('.\\Features_sets/'+ 'Test_MELandDeltas.pkl')\n",
    "\n",
    "\n",
    "df_TRAIN_final=pd.DataFrame() \n",
    "df_TEST_final=pd.DataFrame() \n",
    "df_TRAIN_final, df_TEST_final = split_dataframes( df_cats_MFCC_AND_Deltas, df_dogs_MFCC_AND_Deltas, test_size=0.3)\n",
    "df_TRAIN_final.to_pickle('.\\Features_sets/'+ 'Train_MFCCandDeltas.pkl')  \n",
    "df_TEST_final.to_pickle('.\\Features_sets/'+ 'Test_MFCCandDeltas.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
