{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST-data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST-data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/t10k-labels-idx1-ubyte.gz\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/mnist_convnet_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x121971eb8>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/mnist_convnet_model/model.ckpt.\n",
      "INFO:tensorflow:probabilities = [[ 0.10119652  0.10873593  0.09963275  0.09874225  0.09800243  0.10154663\n",
      "   0.09747052  0.09918179  0.0968611   0.09863009]\n",
      " [ 0.10045094  0.09959718  0.1073926   0.09507655  0.09324383  0.10712241\n",
      "   0.09227826  0.10098496  0.09590822  0.10794507]\n",
      " [ 0.09460752  0.09311749  0.09630568  0.09751543  0.10096325  0.10920363\n",
      "   0.10766018  0.101194    0.09726465  0.10216817]\n",
      " [ 0.10983577  0.0953177   0.1063988   0.08476537  0.09245856  0.11366498\n",
      "   0.09351997  0.1000526   0.09991897  0.10406733]\n",
      " [ 0.10134933  0.10324378  0.10237393  0.09076571  0.10154445  0.10175533\n",
      "   0.10203081  0.09861716  0.09391569  0.10440376]\n",
      " [ 0.1017702   0.09510234  0.09437209  0.08876741  0.08137652  0.10358194\n",
      "   0.11190353  0.10055463  0.1092153   0.113356  ]\n",
      " [ 0.0978716   0.10188896  0.09938727  0.10093956  0.09778596  0.10651837\n",
      "   0.10092989  0.09843548  0.09232213  0.10392078]\n",
      " [ 0.09888966  0.09635555  0.09904342  0.0880516   0.09107352  0.11847743\n",
      "   0.11262994  0.10344054  0.09230819  0.09973012]\n",
      " [ 0.11035576  0.09512441  0.10640942  0.09729659  0.10081521  0.09669526\n",
      "   0.111031    0.09717678  0.09533302  0.08976256]\n",
      " [ 0.09776916  0.1059      0.0872554   0.09617426  0.09074439  0.10980838\n",
      "   0.10100033  0.10281732  0.10166091  0.10686993]\n",
      " [ 0.09226624  0.10404485  0.1002735   0.09740478  0.09727313  0.10940212\n",
      "   0.10850821  0.0994829   0.09679542  0.09454886]\n",
      " [ 0.09807251  0.10232954  0.09577429  0.09458072  0.10544742  0.10776816\n",
      "   0.09709894  0.10689405  0.09839673  0.09363758]\n",
      " [ 0.09777983  0.09745984  0.09493589  0.09825084  0.08909174  0.11198986\n",
      "   0.1111185   0.10372863  0.10017146  0.09547336]\n",
      " [ 0.10451244  0.09679805  0.09425768  0.10283674  0.09658701  0.1158117\n",
      "   0.0961237   0.09599581  0.09820998  0.0988669 ]\n",
      " [ 0.10256951  0.10140761  0.09601568  0.08611984  0.09631421  0.10382761\n",
      "   0.11057822  0.10041029  0.10271671  0.10004041]\n",
      " [ 0.10375424  0.10429575  0.09699073  0.09220558  0.08894513  0.10396864\n",
      "   0.09968004  0.100743    0.10549337  0.10392352]\n",
      " [ 0.10458975  0.10327367  0.0957644   0.09499329  0.0949335   0.11326222\n",
      "   0.09638504  0.10259938  0.10110612  0.09309264]\n",
      " [ 0.117443    0.09562306  0.10411642  0.08869048  0.09569323  0.1038944\n",
      "   0.09552477  0.1037581   0.1017387   0.09351787]\n",
      " [ 0.09639241  0.1010432   0.09582189  0.09151085  0.08720303  0.10829417\n",
      "   0.10422502  0.11601162  0.10605211  0.09344566]\n",
      " [ 0.09792522  0.0993625   0.09487665  0.10391211  0.09711168  0.09839012\n",
      "   0.09580751  0.10447364  0.10263956  0.105501  ]\n",
      " [ 0.10625698  0.10046817  0.0926154   0.09291699  0.09354743  0.10293145\n",
      "   0.10227187  0.10462082  0.09311684  0.11125411]\n",
      " [ 0.09689986  0.09333887  0.098616    0.09567456  0.10778608  0.10353685\n",
      "   0.10197489  0.099622    0.10112887  0.10142206]\n",
      " [ 0.10647649  0.08900192  0.10081042  0.10749277  0.08374775  0.10502844\n",
      "   0.10239581  0.09907991  0.10191185  0.10405462]\n",
      " [ 0.10621848  0.08688577  0.0951091   0.09025251  0.09637041  0.10133521\n",
      "   0.10422932  0.10255931  0.11431839  0.10272159]\n",
      " [ 0.10384621  0.09870495  0.09151828  0.09367184  0.09513962  0.10864636\n",
      "   0.10936912  0.0998722   0.09529892  0.10393252]\n",
      " [ 0.1065186   0.09985936  0.10140918  0.09241039  0.09718543  0.10414191\n",
      "   0.09894671  0.09185731  0.10772185  0.09994927]\n",
      " [ 0.10248084  0.09781912  0.09732221  0.10059495  0.10278905  0.0997736\n",
      "   0.09939279  0.10615336  0.10456576  0.08910832]\n",
      " [ 0.095799    0.10461993  0.09042705  0.09241372  0.0924609   0.10681004\n",
      "   0.09448911  0.10991015  0.11031988  0.10275023]\n",
      " [ 0.09853855  0.08772531  0.10893226  0.09996672  0.09817166  0.10681918\n",
      "   0.0961822   0.09676647  0.10271701  0.10418073]\n",
      " [ 0.09830833  0.10022599  0.0874785   0.10509531  0.09509728  0.1042703\n",
      "   0.10742902  0.10561315  0.09794001  0.09854203]\n",
      " [ 0.109425    0.09694061  0.10680801  0.09635726  0.09916511  0.1001017\n",
      "   0.09689041  0.09210246  0.10289265  0.09931675]\n",
      " [ 0.09790933  0.09186143  0.08468829  0.10569754  0.09960226  0.10955295\n",
      "   0.10471804  0.10566205  0.10519901  0.09510906]\n",
      " [ 0.09843796  0.10015471  0.10241183  0.09189337  0.09265782  0.1047033\n",
      "   0.09463142  0.11059113  0.10897279  0.09554567]\n",
      " [ 0.0964805   0.11220841  0.09557945  0.10106972  0.08823078  0.11293869\n",
      "   0.09982118  0.09396319  0.09952728  0.10018083]\n",
      " [ 0.09709257  0.10238866  0.10929821  0.09806547  0.09499853  0.11054303\n",
      "   0.09908522  0.09251644  0.09192237  0.10408944]\n",
      " [ 0.09523811  0.09114713  0.10001491  0.08754252  0.10680593  0.1084547\n",
      "   0.09695186  0.10134282  0.10984841  0.10265359]\n",
      " [ 0.10619178  0.10235927  0.08845504  0.0908079   0.09307415  0.1076801\n",
      "   0.09544476  0.10641423  0.10927235  0.10030032]\n",
      " [ 0.1062619   0.10670038  0.09710034  0.09626426  0.08833216  0.10449605\n",
      "   0.10119154  0.09905688  0.09906509  0.10153147]\n",
      " [ 0.10114503  0.1074438   0.0982511   0.10622672  0.0850742   0.10680658\n",
      "   0.08988541  0.10310098  0.10498153  0.09708464]\n",
      " [ 0.10345449  0.09692558  0.0939715   0.10268364  0.09406728  0.11388291\n",
      "   0.09947608  0.09710471  0.09505454  0.10337934]\n",
      " [ 0.10378766  0.10047652  0.09984433  0.0959373   0.09337147  0.10702725\n",
      "   0.09785519  0.10342434  0.10518552  0.09309044]\n",
      " [ 0.10547531  0.09418663  0.10706675  0.09830032  0.09083387  0.10741213\n",
      "   0.09712446  0.09801272  0.10117774  0.10041005]\n",
      " [ 0.10272735  0.09921378  0.09761155  0.09477457  0.09974171  0.10788384\n",
      "   0.09748213  0.10315804  0.10035846  0.09704855]\n",
      " [ 0.09758405  0.09321004  0.09901235  0.09117974  0.09428889  0.11759314\n",
      "   0.10554727  0.09570771  0.10248592  0.1033909 ]\n",
      " [ 0.11617882  0.10956837  0.09131661  0.08208259  0.09193872  0.10452658\n",
      "   0.10075338  0.10678994  0.10495509  0.09188988]\n",
      " [ 0.1040839   0.10850506  0.0969786   0.09547706  0.09366535  0.10767923\n",
      "   0.09962328  0.09773819  0.09611871  0.10013068]\n",
      " [ 0.1108802   0.10018662  0.08743533  0.09439315  0.09508169  0.10504716\n",
      "   0.11493099  0.11862767  0.08956457  0.08385264]\n",
      " [ 0.10643299  0.09108913  0.10231456  0.09928668  0.08835867  0.10418879\n",
      "   0.10459957  0.10256317  0.10253278  0.09863363]\n",
      " [ 0.09611695  0.10095639  0.09811371  0.09433682  0.0941366   0.11692103\n",
      "   0.10553624  0.10366073  0.08982287  0.10039867]\n",
      " [ 0.11011159  0.0981853   0.09860972  0.0995106   0.10426326  0.09257008\n",
      "   0.09636122  0.10331964  0.10291461  0.094154  ]\n",
      " [ 0.1190493   0.10771085  0.10341214  0.09049312  0.09276647  0.09861249\n",
      "   0.09535322  0.09657352  0.09982951  0.0961994 ]\n",
      " [ 0.09233181  0.11418512  0.0961378   0.08511962  0.10190639  0.11925917\n",
      "   0.09310233  0.10168868  0.09526972  0.10099932]\n",
      " [ 0.09852563  0.10273977  0.09327709  0.10295303  0.09967726  0.10888518\n",
      "   0.09688891  0.10615841  0.09159181  0.09930293]\n",
      " [ 0.10349981  0.09370229  0.09394056  0.09342612  0.0981798   0.1139306\n",
      "   0.10834303  0.0957998   0.09909759  0.1000804 ]\n",
      " [ 0.09103841  0.10204397  0.09755138  0.08782379  0.09765474  0.11032045\n",
      "   0.09980606  0.11071839  0.10097932  0.10206344]\n",
      " [ 0.10216229  0.0964392   0.09557479  0.0970831   0.08915018  0.11704385\n",
      "   0.10529851  0.09608039  0.09956673  0.10160088]\n",
      " [ 0.10565957  0.10698068  0.09906804  0.09045433  0.0925518   0.10782434\n",
      "   0.10309474  0.09888677  0.09680234  0.09867743]\n",
      " [ 0.10520073  0.10246001  0.08559118  0.09949397  0.08936831  0.10001502\n",
      "   0.10003764  0.10049049  0.10873722  0.10860538]\n",
      " [ 0.10086073  0.08960523  0.08812219  0.09975912  0.10154985  0.11363138\n",
      "   0.10482199  0.09413078  0.10422733  0.1032914 ]\n",
      " [ 0.10032616  0.09353124  0.08923974  0.09789513  0.09701802  0.10201053\n",
      "   0.1019505   0.1102277   0.10489332  0.10290772]\n",
      " [ 0.10710936  0.09309758  0.09766723  0.10350844  0.10425426  0.09633014\n",
      "   0.09776     0.10058219  0.10012063  0.09957023]\n",
      " [ 0.09739254  0.10184913  0.09990811  0.09714016  0.08873124  0.10115073\n",
      "   0.11006113  0.10038358  0.11146683  0.09191655]\n",
      " [ 0.10060403  0.09696668  0.07933142  0.10635082  0.10048632  0.1112643\n",
      "   0.10964211  0.1051742   0.09434122  0.09583885]\n",
      " [ 0.10144457  0.09366985  0.10311524  0.09049672  0.10599016  0.09952936\n",
      "   0.10137345  0.09483273  0.10321132  0.10633664]\n",
      " [ 0.10798983  0.09060257  0.10010147  0.08746435  0.09956884  0.10551999\n",
      "   0.10981718  0.09331598  0.10145143  0.10416837]\n",
      " [ 0.09220622  0.09877841  0.09119908  0.09564796  0.10605127  0.12108647\n",
      "   0.10675869  0.10250453  0.09468592  0.09108151]\n",
      " [ 0.11055604  0.09955055  0.10134993  0.09670026  0.0858022   0.09449972\n",
      "   0.10639376  0.09935974  0.10473341  0.10105442]\n",
      " [ 0.10279337  0.09846592  0.09521341  0.09915365  0.09535596  0.10131744\n",
      "   0.10490192  0.10659426  0.09435291  0.10185121]\n",
      " [ 0.11264435  0.0843348   0.09662649  0.08777955  0.10168417  0.10753414\n",
      "   0.10754301  0.09912535  0.09672212  0.106006  ]\n",
      " [ 0.11270953  0.09907524  0.08690245  0.10066891  0.09084217  0.10504591\n",
      "   0.09580565  0.09658811  0.10819624  0.10416584]\n",
      " [ 0.09965467  0.09853668  0.09560683  0.10513316  0.0979288   0.10239729\n",
      "   0.10458118  0.09837034  0.10576358  0.09202749]\n",
      " [ 0.10158163  0.09376263  0.09806985  0.09931767  0.10478023  0.10363703\n",
      "   0.09966189  0.09923209  0.1002892   0.09966771]\n",
      " [ 0.09538765  0.10559128  0.10326362  0.10208634  0.09269015  0.10096084\n",
      "   0.10421882  0.09617937  0.10804996  0.091572  ]\n",
      " [ 0.10758382  0.10449275  0.08709284  0.10219217  0.0968389   0.11027477\n",
      "   0.09629031  0.1014441   0.09658787  0.09720243]\n",
      " [ 0.10694475  0.09827121  0.09676985  0.08985553  0.09567633  0.10557657\n",
      "   0.09520505  0.09005205  0.10914999  0.1124986 ]\n",
      " [ 0.10538189  0.11047139  0.09956942  0.08793778  0.09524978  0.10794427\n",
      "   0.09991319  0.09151541  0.10116725  0.10084953]\n",
      " [ 0.09623662  0.09962524  0.0968757   0.10276991  0.10235079  0.10496062\n",
      "   0.10502654  0.10155724  0.09766736  0.09292993]\n",
      " [ 0.09875505  0.10753325  0.08677991  0.10255235  0.08698128  0.10943442\n",
      "   0.10763267  0.09674639  0.10516942  0.0984152 ]\n",
      " [ 0.09928504  0.10719521  0.10225623  0.09956592  0.0964429   0.11249243\n",
      "   0.08937205  0.10066043  0.10288828  0.08984157]\n",
      " [ 0.10313963  0.09891017  0.10189296  0.10385484  0.0945405   0.10455763\n",
      "   0.09849723  0.09396715  0.09745129  0.10318862]\n",
      " [ 0.10430279  0.10176292  0.10203673  0.08463283  0.08462871  0.12220083\n",
      "   0.10267244  0.10438706  0.10068322  0.0926925 ]\n",
      " [ 0.10500437  0.08991596  0.0962713   0.09241317  0.09433998  0.10127401\n",
      "   0.11475871  0.10928515  0.10280374  0.09393361]\n",
      " [ 0.11181768  0.09254035  0.10151002  0.09862528  0.09812802  0.10655575\n",
      "   0.08844546  0.09162516  0.10502715  0.10572506]\n",
      " [ 0.1046676   0.09988243  0.08861017  0.10344274  0.08917676  0.10337042\n",
      "   0.10407668  0.11455678  0.09946857  0.09274787]\n",
      " [ 0.10731564  0.10273638  0.09856964  0.09572075  0.08977015  0.1058822\n",
      "   0.08805473  0.09771477  0.11136995  0.10286576]\n",
      " [ 0.10566189  0.08765534  0.10644883  0.08701663  0.09954836  0.10555588\n",
      "   0.10991258  0.09611561  0.09948219  0.10260265]\n",
      " [ 0.09408679  0.10666378  0.09153347  0.08804026  0.09799144  0.11009426\n",
      "   0.10871323  0.09871234  0.10596009  0.09820431]\n",
      " [ 0.10278462  0.10442203  0.09586988  0.09597152  0.09993788  0.10663686\n",
      "   0.09689854  0.09929246  0.10199504  0.09619117]\n",
      " [ 0.10826291  0.09773418  0.09520689  0.09213857  0.08976251  0.12117727\n",
      "   0.10881677  0.09709768  0.09020866  0.09959459]\n",
      " [ 0.10582168  0.11800227  0.09799743  0.09994027  0.09826867  0.10369854\n",
      "   0.08746742  0.08667716  0.09722702  0.1048995 ]\n",
      " [ 0.10507904  0.09328336  0.09283778  0.10192729  0.08866324  0.10890719\n",
      "   0.1048871   0.10726262  0.10131586  0.09583658]\n",
      " [ 0.10055342  0.10055447  0.10754447  0.08999348  0.09193961  0.11283123\n",
      "   0.09196767  0.09731442  0.10498079  0.10232043]\n",
      " [ 0.09262785  0.11336392  0.09921894  0.09016192  0.10002452  0.11316328\n",
      "   0.09851117  0.09006735  0.09769601  0.10516503]\n",
      " [ 0.10034205  0.09557885  0.08917413  0.09915864  0.08950651  0.10555665\n",
      "   0.11216422  0.11427017  0.09831424  0.09593461]\n",
      " [ 0.10147607  0.10244434  0.10840704  0.09190776  0.09438391  0.10278749\n",
      "   0.09342526  0.09886394  0.10649762  0.09980655]\n",
      " [ 0.10415559  0.09246536  0.09530103  0.10868945  0.09648202  0.10343011\n",
      "   0.10568657  0.10194713  0.09520707  0.09663571]\n",
      " [ 0.1029383   0.09862489  0.09852224  0.10486463  0.09357325  0.09883554\n",
      "   0.09618244  0.09128178  0.10253488  0.11264204]\n",
      " [ 0.10203192  0.10374726  0.09223524  0.10048264  0.0952959   0.10488778\n",
      "   0.10315241  0.10562763  0.09395647  0.09858277]\n",
      " [ 0.10469765  0.09456582  0.09580067  0.09872652  0.10520563  0.10055432\n",
      "   0.09919694  0.09676035  0.10540719  0.09908494]\n",
      " [ 0.09619664  0.10308291  0.1026134   0.08979102  0.10217627  0.10502666\n",
      "   0.09827747  0.10216092  0.09620421  0.10447048]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.31609, step = 1\n",
      "INFO:tensorflow:probabilities = [[ 0.09496771  0.10551788  0.09499744  0.09604934  0.09464189  0.09713991\n",
      "   0.10482781  0.10495456  0.10274883  0.10415469]\n",
      " [ 0.10636753  0.09785914  0.10701583  0.09131967  0.0940451   0.10920069\n",
      "   0.09798934  0.10113507  0.10347304  0.09159456]\n",
      " [ 0.11932434  0.08850795  0.09912644  0.09203109  0.09446617  0.10090774\n",
      "   0.11034068  0.09360567  0.09886836  0.10282157]\n",
      " [ 0.10822158  0.08463757  0.10852851  0.08941022  0.09551288  0.10911919\n",
      "   0.10841752  0.11048904  0.09613807  0.08952551]\n",
      " [ 0.11036343  0.1022815   0.0902211   0.09324874  0.09340739  0.09742326\n",
      "   0.09380796  0.1016032   0.11256807  0.10507534]\n",
      " [ 0.10271245  0.09934565  0.09776451  0.09534497  0.10022467  0.09954128\n",
      "   0.09894971  0.10107738  0.097534    0.10750537]\n",
      " [ 0.11092908  0.09201956  0.09908839  0.09963336  0.09251525  0.10375602\n",
      "   0.10721065  0.0988534   0.09886375  0.09713051]\n",
      " [ 0.10244767  0.10719561  0.08920992  0.09529585  0.09324     0.10392722\n",
      "   0.09740815  0.10348818  0.11001302  0.09777434]\n",
      " [ 0.08407047  0.08913755  0.0944895   0.09987164  0.09795536  0.10173555\n",
      "   0.09910423  0.1194756   0.11124011  0.10291997]\n",
      " [ 0.1043434   0.10839253  0.09519175  0.09323226  0.09716013  0.10274884\n",
      "   0.0984221   0.10891134  0.09474656  0.09685107]\n",
      " [ 0.10560726  0.09471662  0.10349429  0.10360417  0.0862286   0.10373762\n",
      "   0.10093561  0.09902699  0.10006254  0.10258636]\n",
      " [ 0.09578273  0.096412    0.10717855  0.09785622  0.09304667  0.10477517\n",
      "   0.10096516  0.09242649  0.10375818  0.10779884]\n",
      " [ 0.09443413  0.10093662  0.10267372  0.09173961  0.0926761   0.10485075\n",
      "   0.09996885  0.11001377  0.10420308  0.09850331]\n",
      " [ 0.10425687  0.10101371  0.10425162  0.09290127  0.08787777  0.1016753\n",
      "   0.10222934  0.10131752  0.10025853  0.10421805]\n",
      " [ 0.10224747  0.10039405  0.1015835   0.09259442  0.0970326   0.1050405\n",
      "   0.09894806  0.09947554  0.09402891  0.10865488]\n",
      " [ 0.11579635  0.08383372  0.1056356   0.09552415  0.10015439  0.10616577\n",
      "   0.10823856  0.09885498  0.09917621  0.08662031]\n",
      " [ 0.10139363  0.10203593  0.09708608  0.09973961  0.10051204  0.10423754\n",
      "   0.09289593  0.09901069  0.10722598  0.09586258]\n",
      " [ 0.10748934  0.09560759  0.09647032  0.09999754  0.09213922  0.10972657\n",
      "   0.1035551   0.09764108  0.09792755  0.09944569]\n",
      " [ 0.10731028  0.10054972  0.10099461  0.09680271  0.0965948   0.09922952\n",
      "   0.0948416   0.0955333   0.10651501  0.10162846]\n",
      " [ 0.10214144  0.08574286  0.10345474  0.09509233  0.09540176  0.10239779\n",
      "   0.10169339  0.10871179  0.10137413  0.10398978]\n",
      " [ 0.11165743  0.10430144  0.09319762  0.08792485  0.08233835  0.11305257\n",
      "   0.10113706  0.10034449  0.10827801  0.09776823]\n",
      " [ 0.10586161  0.08324481  0.10409959  0.10686605  0.08944001  0.10706491\n",
      "   0.08851324  0.09644924  0.11493929  0.10352124]\n",
      " [ 0.10193022  0.0921257   0.10009836  0.08272018  0.10120594  0.10711692\n",
      "   0.10085174  0.1000715   0.1074277   0.10645178]\n",
      " [ 0.10926203  0.10346971  0.09270993  0.10879026  0.09303774  0.10345655\n",
      "   0.10056651  0.08632905  0.1127307   0.08964749]\n",
      " [ 0.10851673  0.1023616   0.1043691   0.09756358  0.09179408  0.10310604\n",
      "   0.09835393  0.0928974   0.10101461  0.10002296]\n",
      " [ 0.10305334  0.0998098   0.09241627  0.08934502  0.09586451  0.10298435\n",
      "   0.10985568  0.1011963   0.09189475  0.11357999]\n",
      " [ 0.10012984  0.0949228   0.09793092  0.09008483  0.09498582  0.09926508\n",
      "   0.10210795  0.11361574  0.10020275  0.10675429]\n",
      " [ 0.10810538  0.08466534  0.0914108   0.08672892  0.098224    0.10805131\n",
      "   0.10535076  0.10918225  0.10456175  0.10371954]\n",
      " [ 0.09566261  0.09175338  0.09384832  0.11060843  0.10085537  0.10222763\n",
      "   0.10450681  0.09723342  0.10031968  0.1029843 ]\n",
      " [ 0.09451871  0.09601983  0.10094304  0.10053071  0.08861274  0.11883062\n",
      "   0.0953751   0.09983469  0.09588563  0.10944898]\n",
      " [ 0.10423058  0.09523692  0.09305566  0.09876457  0.10159744  0.09895615\n",
      "   0.10284718  0.10770278  0.10280138  0.0948074 ]\n",
      " [ 0.10017082  0.09841897  0.09456085  0.09398926  0.09506738  0.10836075\n",
      "   0.10742906  0.10174163  0.09985684  0.1004044 ]\n",
      " [ 0.10140442  0.10530785  0.09303157  0.09903011  0.08685919  0.1102953\n",
      "   0.10109818  0.11054328  0.09312798  0.09930211]\n",
      " [ 0.09779423  0.09363492  0.09827425  0.10665021  0.08517605  0.10148709\n",
      "   0.10799675  0.10923795  0.11058954  0.08915903]\n",
      " [ 0.09726159  0.10138749  0.10465626  0.09015366  0.10218443  0.11078703\n",
      "   0.1086173   0.102037    0.09680517  0.08611009]\n",
      " [ 0.1020273   0.09958793  0.10080661  0.0955264   0.09586948  0.1102543\n",
      "   0.10010925  0.08828483  0.10720625  0.10032757]\n",
      " [ 0.09869721  0.0903541   0.10014106  0.09467166  0.10280207  0.09836039\n",
      "   0.09368648  0.1056344   0.10927832  0.10637424]\n",
      " [ 0.1052895   0.09177643  0.09132224  0.09805039  0.09538709  0.11194067\n",
      "   0.09973651  0.11462698  0.09786631  0.09400392]\n",
      " [ 0.10094822  0.09899112  0.10414938  0.09584783  0.09683846  0.10930634\n",
      "   0.09420419  0.09827346  0.09244856  0.10899251]\n",
      " [ 0.09883329  0.11006157  0.11313816  0.0861294   0.08759337  0.1088589\n",
      "   0.0866623   0.10301749  0.10177283  0.10393275]\n",
      " [ 0.10455618  0.09077855  0.10031643  0.10376234  0.09905111  0.10710775\n",
      "   0.09915262  0.08872127  0.10200345  0.10455026]\n",
      " [ 0.10451934  0.10528996  0.09923799  0.09062314  0.09510002  0.12573385\n",
      "   0.09278449  0.09655452  0.09748861  0.09266799]\n",
      " [ 0.10677022  0.09310584  0.09021996  0.10346983  0.09170708  0.10451612\n",
      "   0.10028144  0.10687954  0.10378334  0.09926662]\n",
      " [ 0.09913827  0.09908715  0.10177445  0.10078523  0.09985535  0.10138124\n",
      "   0.11032265  0.09366759  0.09883638  0.09515173]\n",
      " [ 0.10016789  0.10668868  0.08638536  0.10026728  0.09150239  0.10584869\n",
      "   0.10444453  0.10758135  0.100172    0.09694189]\n",
      " [ 0.10011233  0.11409344  0.09074481  0.09732126  0.08196179  0.10602398\n",
      "   0.10627964  0.10590512  0.10124738  0.09631027]\n",
      " [ 0.10665332  0.09691832  0.08813676  0.09513487  0.09648409  0.12332268\n",
      "   0.10945752  0.09139874  0.09484722  0.0976465 ]\n",
      " [ 0.1046395   0.10384205  0.09930171  0.09471103  0.10089753  0.10328432\n",
      "   0.10325849  0.0976449   0.09863578  0.09378474]\n",
      " [ 0.09976166  0.09820864  0.09244011  0.08893392  0.10798208  0.11322159\n",
      "   0.10554077  0.09874167  0.09358316  0.10158647]\n",
      " [ 0.09753301  0.09923111  0.10239553  0.10459083  0.09154557  0.10663206\n",
      "   0.09780407  0.09741008  0.10035237  0.10250539]\n",
      " [ 0.09954864  0.09512604  0.10621919  0.09358609  0.09141506  0.09940342\n",
      "   0.10012043  0.09184118  0.10690456  0.11583531]\n",
      " [ 0.10019885  0.1073918   0.09940086  0.09024727  0.09871207  0.10579664\n",
      "   0.09611964  0.1059292   0.09930212  0.09690157]\n",
      " [ 0.11009221  0.10363467  0.10228495  0.08436061  0.10014491  0.10146474\n",
      "   0.10310922  0.09938542  0.10984255  0.08568069]\n",
      " [ 0.09921207  0.1041427   0.09982157  0.10356756  0.0916632   0.10406628\n",
      "   0.10583096  0.09703578  0.10037816  0.09428173]\n",
      " [ 0.10278833  0.09855402  0.09996485  0.09859032  0.10040568  0.09230051\n",
      "   0.11222881  0.10497095  0.09773656  0.09246001]\n",
      " [ 0.09599312  0.09895938  0.10159035  0.10584704  0.09994932  0.10153668\n",
      "   0.10682711  0.09366751  0.09716998  0.09845956]\n",
      " [ 0.09626706  0.10299646  0.10293443  0.09530366  0.09372326  0.10297461\n",
      "   0.10325056  0.10543748  0.10594476  0.09116775]\n",
      " [ 0.1079042   0.0904255   0.09545542  0.10051363  0.0892433   0.11318392\n",
      "   0.09802529  0.09625361  0.10354717  0.10544796]\n",
      " [ 0.10825182  0.09814828  0.09072886  0.08771147  0.10148898  0.10254484\n",
      "   0.1074338   0.10050137  0.1121324   0.09105816]\n",
      " [ 0.10187818  0.10354144  0.08810546  0.1016922   0.11083193  0.10031717\n",
      "   0.09022272  0.10090306  0.102534    0.09997392]\n",
      " [ 0.10400787  0.09146744  0.09363439  0.09984626  0.09539794  0.10177667\n",
      "   0.09804594  0.10083865  0.10466748  0.11031739]\n",
      " [ 0.10428495  0.08992691  0.10321097  0.09794117  0.08396509  0.11492139\n",
      "   0.09800865  0.10435528  0.09376009  0.1096255 ]\n",
      " [ 0.09132694  0.09480599  0.0956006   0.0817077   0.09356879  0.11511226\n",
      "   0.08898043  0.10174892  0.13106333  0.10608496]\n",
      " [ 0.10055453  0.09843203  0.10457484  0.10428073  0.09110697  0.10323593\n",
      "   0.09716991  0.09761071  0.1005732   0.10246108]\n",
      " [ 0.10381401  0.09010047  0.09309273  0.08298477  0.10974628  0.10299293\n",
      "   0.11498813  0.09337012  0.09818359  0.11072693]\n",
      " [ 0.10470112  0.09866857  0.08573379  0.0865963   0.08619402  0.1061964\n",
      "   0.1165766   0.09987654  0.10894659  0.10651011]\n",
      " [ 0.11066046  0.10653955  0.09942321  0.10494006  0.08568915  0.09778722\n",
      "   0.09822845  0.10009661  0.09460977  0.10202546]\n",
      " [ 0.0998351   0.09542195  0.09918667  0.09029033  0.09793676  0.10761807\n",
      "   0.11202637  0.10703968  0.09926131  0.09138379]\n",
      " [ 0.1070836   0.08986047  0.08485288  0.09211706  0.11047208  0.10820182\n",
      "   0.11274415  0.09516174  0.08969533  0.10981082]\n",
      " [ 0.10765104  0.09912488  0.0965248   0.09624428  0.10069243  0.1056179\n",
      "   0.1035419   0.09602783  0.10032908  0.09424595]\n",
      " [ 0.10857262  0.11519393  0.0895538   0.08492914  0.09769684  0.09891093\n",
      "   0.10305908  0.10032786  0.09981946  0.10193628]\n",
      " [ 0.1075941   0.08772777  0.10569214  0.0902547   0.09014636  0.11403249\n",
      "   0.10716296  0.09297811  0.09975707  0.10465433]\n",
      " [ 0.0962363   0.10553047  0.07830834  0.09515947  0.09571252  0.10540793\n",
      "   0.10967953  0.09882838  0.10761303  0.10752404]\n",
      " [ 0.10385337  0.10200026  0.09397992  0.08793896  0.09716398  0.11191091\n",
      "   0.09784492  0.08977519  0.100247    0.11528546]\n",
      " [ 0.10097713  0.09350028  0.09868738  0.09644629  0.09264575  0.10843167\n",
      "   0.1112569   0.09988001  0.09715114  0.10102338]\n",
      " [ 0.10291418  0.10224281  0.1064117   0.0976331   0.08674714  0.09176415\n",
      "   0.08979509  0.10080478  0.12254716  0.09913982]\n",
      " [ 0.10028832  0.10944014  0.09196869  0.091842    0.09884583  0.10996238\n",
      "   0.10354406  0.10064002  0.09847158  0.09499694]\n",
      " [ 0.10376385  0.09852704  0.10931266  0.09758639  0.10379282  0.09639374\n",
      "   0.10187001  0.10169197  0.10062512  0.08643644]\n",
      " [ 0.10125077  0.09447094  0.10177918  0.10291933  0.09691503  0.10505415\n",
      "   0.09590755  0.09971711  0.1052144   0.0967716 ]\n",
      " [ 0.09955127  0.10238203  0.10119625  0.10391419  0.09405392  0.0959443\n",
      "   0.09444526  0.09867827  0.11422192  0.09561264]\n",
      " [ 0.1083791   0.09855878  0.09842945  0.09708808  0.097408    0.10386223\n",
      "   0.09382433  0.09033347  0.10536005  0.10675656]\n",
      " [ 0.09872367  0.09986164  0.09028815  0.08331541  0.09547766  0.10610234\n",
      "   0.11194893  0.09708247  0.1023498   0.11484995]\n",
      " [ 0.10160719  0.10390685  0.08595391  0.08582161  0.08765     0.10582241\n",
      "   0.103467    0.10947597  0.10208543  0.1142097 ]\n",
      " [ 0.1047444   0.09508909  0.10068601  0.09698915  0.10763983  0.10296551\n",
      "   0.09595103  0.09347162  0.10688142  0.09558196]\n",
      " [ 0.1037094   0.10604044  0.09586786  0.08236911  0.09117471  0.11214003\n",
      "   0.1074904   0.09829882  0.10359892  0.09931026]\n",
      " [ 0.10513572  0.09436298  0.10221714  0.09093399  0.09761421  0.11089107\n",
      "   0.09766095  0.09706482  0.10270052  0.10141858]\n",
      " [ 0.10897709  0.10222071  0.1033621   0.09913563  0.08893227  0.097882\n",
      "   0.10267209  0.09963553  0.09688742  0.10029516]\n",
      " [ 0.09819235  0.08859962  0.1052526   0.09203459  0.10558435  0.10389812\n",
      "   0.11375507  0.1018493   0.09757376  0.09326026]\n",
      " [ 0.09558561  0.11783544  0.08688756  0.09922644  0.08926121  0.1035924\n",
      "   0.11029699  0.1029796   0.09791415  0.09642057]\n",
      " [ 0.10954952  0.10168947  0.1085013   0.09250059  0.08663764  0.11261487\n",
      "   0.09170719  0.0970414   0.10099981  0.09875815]\n",
      " [ 0.11078276  0.09577239  0.09726054  0.09184356  0.09195109  0.0988046\n",
      "   0.10256594  0.10544501  0.10181529  0.10375876]\n",
      " [ 0.10686658  0.09483323  0.09716412  0.09802774  0.09673982  0.10780734\n",
      "   0.09615536  0.10070697  0.09984554  0.10185333]\n",
      " [ 0.11217567  0.10449433  0.09564321  0.09821282  0.0868153   0.10396651\n",
      "   0.09258304  0.10048168  0.10338797  0.10223946]\n",
      " [ 0.10718165  0.10441909  0.09805566  0.09957058  0.09303568  0.10349733\n",
      "   0.10099311  0.09972008  0.10396683  0.08955996]\n",
      " [ 0.09738956  0.08983611  0.10109013  0.10572582  0.10295264  0.10428709\n",
      "   0.10139866  0.10028433  0.10082841  0.09620718]\n",
      " [ 0.09344397  0.09312817  0.09547199  0.09804869  0.10433614  0.09947058\n",
      "   0.10307812  0.10785267  0.10280091  0.10236877]\n",
      " [ 0.10685961  0.09170651  0.09416696  0.09895118  0.09215426  0.11153416\n",
      "   0.10996995  0.10517783  0.08881922  0.10066035]\n",
      " [ 0.10480823  0.10180587  0.10084675  0.08720435  0.09099762  0.10784536\n",
      "   0.10024803  0.1063505   0.10107397  0.09881934]\n",
      " [ 0.10970833  0.10048357  0.10349582  0.08642966  0.09045296  0.10825412\n",
      "   0.10029544  0.09627393  0.10011846  0.10448771]\n",
      " [ 0.11202     0.10009734  0.09236789  0.08959317  0.11136407  0.09620261\n",
      "   0.09649205  0.09369555  0.10195927  0.10620804]] (18.497 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.74999\n",
      "INFO:tensorflow:probabilities = [[ 0.10735097  0.09533235  0.09976765  0.09969304  0.09386881  0.10142221\n",
      "   0.10017084  0.09437414  0.10185797  0.10616208]\n",
      " [ 0.10823157  0.09054787  0.10368498  0.10323229  0.10022669  0.10883357\n",
      "   0.09295722  0.09795441  0.09743345  0.09689789]\n",
      " [ 0.10873149  0.10281241  0.09479167  0.09491349  0.08841612  0.10573997\n",
      "   0.10491613  0.09996168  0.09966063  0.10005637]\n",
      " [ 0.10322154  0.10120772  0.09412602  0.09948219  0.10934225  0.09675926\n",
      "   0.09496417  0.09985071  0.10421745  0.09682856]\n",
      " [ 0.11003383  0.10474432  0.1085261   0.09781957  0.08622473  0.1038465\n",
      "   0.09870643  0.09005193  0.10719463  0.092852  ]\n",
      " [ 0.106284    0.10679369  0.09633693  0.10606456  0.08644408  0.10672703\n",
      "   0.10006319  0.1003404   0.10015637  0.09078977]\n",
      " [ 0.09826908  0.09558411  0.0956267   0.11012454  0.09839504  0.10020508\n",
      "   0.09609411  0.09826744  0.11003856  0.09739534]\n",
      " [ 0.11001289  0.09894972  0.09526482  0.09685829  0.09148066  0.10839882\n",
      "   0.10062072  0.09648076  0.10477373  0.09715956]\n",
      " [ 0.10120601  0.09671081  0.09523847  0.09593158  0.10876188  0.10097451\n",
      "   0.10124757  0.10421097  0.09474915  0.10096902]\n",
      " [ 0.09318795  0.09844125  0.08971433  0.09909809  0.0956599   0.10753737\n",
      "   0.10501782  0.09547177  0.11305725  0.1028143 ]\n",
      " [ 0.09410249  0.11305702  0.08495241  0.09110926  0.09774692  0.11078734\n",
      "   0.10998832  0.10124214  0.09174666  0.10526747]\n",
      " [ 0.09620353  0.10128219  0.0973988   0.10719654  0.09052464  0.10485894\n",
      "   0.09876638  0.10408046  0.10278353  0.09690505]\n",
      " [ 0.10272501  0.09811271  0.09210463  0.11002014  0.09694757  0.09239829\n",
      "   0.092848    0.10699067  0.1031465   0.10470648]\n",
      " [ 0.10315506  0.09362429  0.10136358  0.09871702  0.09825669  0.10432138\n",
      "   0.10881662  0.10349464  0.09923047  0.0890203 ]\n",
      " [ 0.10309429  0.09642979  0.09478174  0.09219202  0.09732926  0.10627829\n",
      "   0.08963177  0.10472118  0.11450868  0.101033  ]\n",
      " [ 0.10411356  0.09331065  0.09103678  0.09194563  0.09578983  0.10671653\n",
      "   0.10183263  0.09989265  0.11148465  0.10387713]\n",
      " [ 0.10664033  0.09527302  0.10118783  0.08504523  0.08878618  0.11022642\n",
      "   0.11333176  0.10240348  0.10413419  0.09297147]\n",
      " [ 0.10906915  0.09561532  0.0991751   0.09949144  0.0867383   0.11136449\n",
      "   0.10254786  0.10225499  0.09587821  0.09786515]\n",
      " [ 0.10005145  0.1031701   0.09805692  0.10498985  0.09301232  0.09346986\n",
      "   0.10086656  0.08821843  0.10979904  0.10836544]\n",
      " [ 0.10147569  0.1040349   0.10238633  0.09751866  0.09296997  0.09847848\n",
      "   0.0948859   0.09941204  0.11093581  0.09790224]\n",
      " [ 0.1073529   0.10375603  0.09271805  0.09424383  0.09641627  0.09978914\n",
      "   0.09939668  0.10189832  0.10700943  0.09741925]\n",
      " [ 0.10185788  0.08903375  0.11410467  0.10533653  0.0931081   0.1008692\n",
      "   0.09819041  0.08870624  0.10850047  0.1002928 ]\n",
      " [ 0.09839185  0.08913633  0.10790636  0.08941901  0.09056743  0.10516028\n",
      "   0.10588762  0.10760856  0.11281042  0.09311219]\n",
      " [ 0.10499719  0.09964272  0.09333013  0.09148906  0.09368885  0.10875823\n",
      "   0.09974561  0.09646168  0.10912839  0.10275812]\n",
      " [ 0.10588845  0.09956396  0.0920103   0.08608997  0.10138851  0.10226068\n",
      "   0.10966992  0.10271372  0.10448404  0.09593043]\n",
      " [ 0.09739374  0.10163853  0.09251218  0.09877548  0.0902277   0.1015076\n",
      "   0.10764409  0.11741237  0.10200168  0.09088663]\n",
      " [ 0.10621462  0.09738325  0.10617221  0.08356681  0.08714457  0.09708755\n",
      "   0.10898262  0.10191584  0.1064317   0.10510079]\n",
      " [ 0.09851336  0.10084525  0.09628544  0.0986559   0.09698524  0.11018746\n",
      "   0.10018931  0.09863908  0.10077107  0.09892788]\n",
      " [ 0.12259857  0.09412663  0.09658527  0.10848238  0.08334383  0.10095543\n",
      "   0.09095851  0.1000201   0.11037507  0.0925542 ]\n",
      " [ 0.09848224  0.09623947  0.09882111  0.10101072  0.09383926  0.09788001\n",
      "   0.09997942  0.10317723  0.0985803   0.11199021]\n",
      " [ 0.11176306  0.08657835  0.10354995  0.0929718   0.09511261  0.10815118\n",
      "   0.09883901  0.10342464  0.10484802  0.09476141]\n",
      " [ 0.11633984  0.10679725  0.08424585  0.09865738  0.0895523   0.10106848\n",
      "   0.10521524  0.09973119  0.10497954  0.09341291]\n",
      " [ 0.10535723  0.10228957  0.0953343   0.0985731   0.09655654  0.10157264\n",
      "   0.09266368  0.10741469  0.10084462  0.09939359]\n",
      " [ 0.10592514  0.10824068  0.11071848  0.08637004  0.09331123  0.10927313\n",
      "   0.08915287  0.09476587  0.10790303  0.09433947]\n",
      " [ 0.11182369  0.098289    0.10302127  0.09884408  0.09181272  0.10446548\n",
      "   0.0870298   0.09569672  0.10755464  0.10146259]\n",
      " [ 0.09557556  0.09679572  0.10095403  0.09727616  0.09417961  0.10131752\n",
      "   0.09973357  0.10815252  0.10532305  0.10069229]\n",
      " [ 0.10745566  0.10132314  0.09267326  0.09208195  0.09733298  0.1054064\n",
      "   0.10689511  0.10947309  0.09750181  0.08985665]\n",
      " [ 0.09291828  0.08310438  0.10789101  0.10385894  0.10642169  0.12734431\n",
      "   0.09595672  0.08711313  0.09550712  0.09988437]\n",
      " [ 0.08903467  0.10508464  0.08964005  0.09507473  0.09199417  0.10179589\n",
      "   0.1033098   0.10953565  0.1073576   0.10717285]\n",
      " [ 0.0930027   0.105623    0.09755065  0.1050936   0.09090806  0.10818963\n",
      "   0.10506999  0.09361226  0.10025156  0.10069858]\n",
      " [ 0.11037153  0.09708571  0.09308638  0.09143008  0.09647673  0.10433378\n",
      "   0.10498831  0.08997127  0.10397827  0.10827796]\n",
      " [ 0.09204989  0.09613656  0.0973611   0.10382562  0.09537611  0.10371883\n",
      "   0.11148899  0.10250486  0.0989356   0.09860241]\n",
      " [ 0.10783409  0.09740154  0.09979501  0.09444216  0.09541046  0.109343\n",
      "   0.10275096  0.10224592  0.09441711  0.09635973]\n",
      " [ 0.10633136  0.1034931   0.09436464  0.09253526  0.08533441  0.11748146\n",
      "   0.09115972  0.10632303  0.10891206  0.09406496]\n",
      " [ 0.10403215  0.10170424  0.09989777  0.09901555  0.1118615   0.09571569\n",
      "   0.0992024   0.09495449  0.1009964   0.09261976]\n",
      " [ 0.11294352  0.09649792  0.09698903  0.10377431  0.0904105   0.10635173\n",
      "   0.09709781  0.0963702   0.10122112  0.09834385]\n",
      " [ 0.11307231  0.09152085  0.09841859  0.08172379  0.09392104  0.11442208\n",
      "   0.09080718  0.098401    0.10926942  0.10844377]\n",
      " [ 0.11124033  0.09475674  0.1057186   0.09820444  0.08703194  0.10031676\n",
      "   0.10045707  0.09138394  0.110932    0.09995816]\n",
      " [ 0.10398101  0.08929902  0.09535236  0.10044432  0.10178589  0.10485595\n",
      "   0.09529512  0.0994037   0.10639761  0.103185  ]\n",
      " [ 0.1086783   0.10702496  0.10272247  0.09763301  0.08983414  0.11020749\n",
      "   0.09391976  0.09127841  0.09683781  0.10186362]\n",
      " [ 0.09968869  0.09769279  0.10108013  0.100127    0.09792195  0.10171434\n",
      "   0.10277486  0.09970717  0.10811465  0.09117847]\n",
      " [ 0.09632654  0.09585373  0.1037438   0.09503692  0.10439377  0.10283274\n",
      "   0.09703992  0.09872039  0.10609872  0.09995339]\n",
      " [ 0.09952406  0.09426667  0.09843862  0.09738757  0.10279635  0.10458971\n",
      "   0.10007719  0.10684635  0.10138947  0.09468403]\n",
      " [ 0.10689519  0.11041751  0.09781994  0.09883706  0.08455133  0.10879885\n",
      "   0.0917379   0.09150839  0.10651309  0.10292074]\n",
      " [ 0.10262886  0.1011474   0.09179826  0.09426022  0.09183338  0.10886314\n",
      "   0.10574049  0.1103542   0.10002568  0.09334841]\n",
      " [ 0.10356314  0.09798881  0.08663839  0.10052357  0.08951304  0.107812\n",
      "   0.09756409  0.10512722  0.10361398  0.1076557 ]\n",
      " [ 0.1039267   0.10867297  0.08689921  0.09695281  0.08781876  0.0995041\n",
      "   0.10135611  0.09961057  0.12057677  0.09468199]\n",
      " [ 0.10559801  0.10521143  0.08478387  0.10665321  0.10094112  0.10160293\n",
      "   0.0907533   0.09913547  0.10723393  0.0980868 ]\n",
      " [ 0.09830772  0.10520156  0.09504657  0.08903476  0.09949742  0.10254025\n",
      "   0.10087638  0.10193681  0.10037966  0.10717884]\n",
      " [ 0.09897182  0.09001505  0.10860187  0.08696292  0.09617225  0.10804462\n",
      "   0.11068384  0.10173289  0.09527566  0.10353901]\n",
      " [ 0.09873534  0.09028292  0.09996468  0.09203289  0.10375004  0.10077886\n",
      "   0.10118131  0.10113069  0.10032593  0.11181736]\n",
      " [ 0.10617248  0.08398069  0.09143276  0.10339887  0.10576789  0.10835114\n",
      "   0.1015902   0.1011591   0.09995872  0.09818806]\n",
      " [ 0.09852461  0.08418909  0.09701537  0.0919797   0.09364665  0.11948203\n",
      "   0.09757573  0.1054213   0.09117819  0.12098737]\n",
      " [ 0.09957716  0.10220151  0.08948077  0.0837793   0.10114471  0.10808286\n",
      "   0.1115695   0.10465187  0.10116166  0.09835067]\n",
      " [ 0.09922023  0.10654914  0.09584578  0.09997326  0.09553904  0.09859134\n",
      "   0.09888458  0.10790133  0.10384024  0.09365503]\n",
      " [ 0.10675202  0.10468698  0.08989552  0.10354391  0.09769703  0.10830899\n",
      "   0.09663697  0.0935643   0.10417074  0.09474354]\n",
      " [ 0.10147505  0.1023348   0.09403483  0.09743777  0.10264317  0.09555353\n",
      "   0.09649306  0.10051093  0.1003336   0.1091832 ]\n",
      " [ 0.10194531  0.09343304  0.09614561  0.09575192  0.09084756  0.10854582\n",
      "   0.10815854  0.0991258   0.10571041  0.10033602]\n",
      " [ 0.10538799  0.09149084  0.10033324  0.10036977  0.09551807  0.10203162\n",
      "   0.10564765  0.09121168  0.1055826   0.10242656]\n",
      " [ 0.11403538  0.09549471  0.10309386  0.09232297  0.08668131  0.11134259\n",
      "   0.10328555  0.08976082  0.10108817  0.10289463]\n",
      " [ 0.08993191  0.09771919  0.10456485  0.09584922  0.08870438  0.10240775\n",
      "   0.09618958  0.11141872  0.10135303  0.1118613 ]\n",
      " [ 0.10234167  0.08597387  0.10570526  0.09799057  0.09701397  0.10326503\n",
      "   0.11904081  0.10165468  0.10454931  0.0824649 ]\n",
      " [ 0.10424964  0.09035056  0.09843748  0.09307583  0.08665657  0.10887482\n",
      "   0.1140535   0.10750638  0.09820291  0.09859228]\n",
      " [ 0.10624635  0.10424531  0.12093463  0.09378994  0.08832718  0.09456794\n",
      "   0.09706555  0.09877934  0.10405826  0.09198552]\n",
      " [ 0.10311013  0.09372774  0.0939324   0.09371499  0.09265003  0.10910265\n",
      "   0.10780602  0.10345497  0.10372731  0.0987738 ]\n",
      " [ 0.1079182   0.10016011  0.09404118  0.0985745   0.09022207  0.10634632\n",
      "   0.09681135  0.11076446  0.09980056  0.09536126]\n",
      " [ 0.11469655  0.1047818   0.09777199  0.1058362   0.08896466  0.10148394\n",
      "   0.09052522  0.10511437  0.09830005  0.09252526]\n",
      " [ 0.10010886  0.09741408  0.09802242  0.10267608  0.08477736  0.10266539\n",
      "   0.1093194   0.10804987  0.11012602  0.08684055]\n",
      " [ 0.09795946  0.09442512  0.09835382  0.10391242  0.09554396  0.10059444\n",
      "   0.10616146  0.10275067  0.10866149  0.09163714]\n",
      " [ 0.10112862  0.09654649  0.1036213   0.1015588   0.09732511  0.10206445\n",
      "   0.09603581  0.10194049  0.0983642   0.1014147 ]\n",
      " [ 0.10277915  0.09735172  0.1020975   0.08905408  0.09442441  0.10403194\n",
      "   0.10327726  0.09735288  0.10748067  0.10215048]\n",
      " [ 0.10982357  0.10894731  0.10319524  0.09967393  0.09156474  0.1000411\n",
      "   0.09459341  0.0999658   0.09234308  0.09985182]\n",
      " [ 0.10578314  0.10489322  0.09464256  0.10422968  0.1018856   0.10393543\n",
      "   0.09652325  0.09467591  0.09143301  0.10199825]\n",
      " [ 0.11040759  0.10900413  0.10419443  0.09261178  0.0942445   0.1086053\n",
      "   0.09249035  0.09352585  0.09934238  0.09557366]\n",
      " [ 0.10121702  0.08870621  0.10679916  0.09107212  0.10045912  0.11118376\n",
      "   0.10668732  0.08838572  0.10055947  0.10493013]\n",
      " [ 0.10217684  0.0970166   0.10062233  0.09683076  0.08208384  0.1065707\n",
      "   0.10085189  0.09936689  0.10631563  0.10816447]\n",
      " [ 0.09092654  0.09113131  0.09589124  0.10167074  0.09249182  0.10020451\n",
      "   0.10373799  0.10093439  0.1164436   0.10656787]\n",
      " [ 0.10902829  0.09810837  0.08815302  0.09161981  0.11054865  0.10169131\n",
      "   0.10140733  0.09756444  0.10606118  0.09581754]\n",
      " [ 0.09857712  0.09084877  0.08900539  0.08756717  0.09731106  0.10367952\n",
      "   0.10488749  0.11392193  0.11077818  0.10342337]\n",
      " [ 0.10185433  0.10561419  0.09698527  0.09591176  0.09234724  0.10857162\n",
      "   0.1006759   0.10431077  0.10062759  0.0931013 ]\n",
      " [ 0.0936538   0.1014968   0.08831804  0.08899294  0.09607871  0.1032931\n",
      "   0.10213466  0.11521535  0.1055089   0.1053077 ]\n",
      " [ 0.09649334  0.09467809  0.09955727  0.0955117   0.10649331  0.10184807\n",
      "   0.09943404  0.10902776  0.09441946  0.10253692]\n",
      " [ 0.10776635  0.10249044  0.10117264  0.10368594  0.09648363  0.09825115\n",
      "   0.10035691  0.09398445  0.09428662  0.10152189]\n",
      " [ 0.09980778  0.10434389  0.10004293  0.0949721   0.10374072  0.09992601\n",
      "   0.09232475  0.10233834  0.10477156  0.09773196]\n",
      " [ 0.09997586  0.10046196  0.09097729  0.10506675  0.10028619  0.1120622\n",
      "   0.10187182  0.09802484  0.09363995  0.09763314]\n",
      " [ 0.10873266  0.08580348  0.09215222  0.10020698  0.09402462  0.10963386\n",
      "   0.10999068  0.09382776  0.1027524   0.10287531]\n",
      " [ 0.09883818  0.09218108  0.09180931  0.09311332  0.088728    0.10802244\n",
      "   0.11136936  0.10577343  0.10229588  0.10786907]\n",
      " [ 0.09568655  0.10316407  0.09561208  0.09744741  0.09527489  0.11005212\n",
      "   0.0960711   0.09147631  0.10535008  0.1098654 ]\n",
      " [ 0.09217884  0.10009578  0.08971227  0.09678357  0.1121073   0.10164753\n",
      "   0.09982582  0.10542137  0.10297859  0.09924892]\n",
      " [ 0.10810978  0.09690572  0.10984101  0.09448782  0.09549755  0.10136472\n",
      "   0.10262842  0.09101047  0.09653059  0.10362391]] (17.870 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.29908, step = 101 (36.365 sec)\n",
      "INFO:tensorflow:probabilities = [[ 0.10378005  0.09170397  0.11249231  0.08306099  0.09179293  0.1068555\n",
      "   0.10322651  0.10064997  0.10394394  0.10249381]\n",
      " [ 0.1115613   0.10299467  0.09219026  0.09513423  0.09550052  0.10332758\n",
      "   0.09792981  0.10138438  0.09911951  0.10085776]\n",
      " [ 0.1000192   0.09857919  0.09805644  0.10525975  0.09579352  0.10045713\n",
      "   0.09840276  0.10216736  0.09904744  0.1022172 ]\n",
      " [ 0.09906471  0.09431395  0.09255715  0.10285024  0.10825022  0.10637647\n",
      "   0.0914254   0.10632728  0.10530252  0.09353203]\n",
      " [ 0.09215972  0.10220358  0.11172979  0.09981942  0.10014782  0.1004104\n",
      "   0.09982836  0.10462033  0.1035866   0.08549402]\n",
      " [ 0.09459554  0.09157187  0.10737744  0.10226867  0.09493515  0.10338718\n",
      "   0.10179905  0.1002315   0.10180534  0.10202821]\n",
      " [ 0.11209546  0.08893888  0.11102179  0.09772573  0.08377678  0.10032044\n",
      "   0.1095339   0.09439757  0.1009946   0.10119487]\n",
      " [ 0.10728913  0.10089346  0.09248012  0.09730009  0.09825307  0.09738848\n",
      "   0.10388543  0.10552671  0.1018464   0.0951371 ]\n",
      " [ 0.10054887  0.09669854  0.09485172  0.10017367  0.09540255  0.09969056\n",
      "   0.09819666  0.10081249  0.10566345  0.10796142]\n",
      " [ 0.11911868  0.10925383  0.09508928  0.09183583  0.08769222  0.10601579\n",
      "   0.09179036  0.09401016  0.11059082  0.09460298]\n",
      " [ 0.11202692  0.10330877  0.09963003  0.09919598  0.09949422  0.09386072\n",
      "   0.09400233  0.10654604  0.10306598  0.08886913]\n",
      " [ 0.10318361  0.09006142  0.1018237   0.10259855  0.09554291  0.10376541\n",
      "   0.10367909  0.09327699  0.10151974  0.10454854]\n",
      " [ 0.11353447  0.08945597  0.0988638   0.09049555  0.09646884  0.1090549\n",
      "   0.10849059  0.09913943  0.09628605  0.09821043]\n",
      " [ 0.10224897  0.09753815  0.10653368  0.09059817  0.10640907  0.09874069\n",
      "   0.09695311  0.09726714  0.10343596  0.10027505]\n",
      " [ 0.10219623  0.10128456  0.09841024  0.09364149  0.09584845  0.10387285\n",
      "   0.0902506   0.09910817  0.11631957  0.09906784]\n",
      " [ 0.09410279  0.09800122  0.10663985  0.08690903  0.09984527  0.10388987\n",
      "   0.10856472  0.10281584  0.10184269  0.09738885]\n",
      " [ 0.10051137  0.10023023  0.09905613  0.0943035   0.09173202  0.10062015\n",
      "   0.09695324  0.10044678  0.11072461  0.10542192]\n",
      " [ 0.10220846  0.08693619  0.0995114   0.09480806  0.0962381   0.09972497\n",
      "   0.1098955   0.10452596  0.10340012  0.10275126]\n",
      " [ 0.10458409  0.10234252  0.10327423  0.10317428  0.09872494  0.10310316\n",
      "   0.09300933  0.10014885  0.09753392  0.09410474]\n",
      " [ 0.10539842  0.10038441  0.09611908  0.10040807  0.09640029  0.09084706\n",
      "   0.09839729  0.10089049  0.10386369  0.10729124]\n",
      " [ 0.10555304  0.10458493  0.08990625  0.09668972  0.0957042   0.09519134\n",
      "   0.1008905   0.10532904  0.10223453  0.1039165 ]\n",
      " [ 0.10255335  0.09295286  0.09891386  0.0946528   0.10014787  0.10291859\n",
      "   0.09363346  0.09390182  0.1147194   0.10560605]\n",
      " [ 0.09774542  0.10025289  0.0936404   0.10109454  0.09788161  0.10207285\n",
      "   0.10898869  0.10277291  0.10124274  0.09430795]\n",
      " [ 0.10876113  0.09151159  0.09401717  0.09182627  0.0912918   0.10394354\n",
      "   0.10661934  0.10087658  0.10387082  0.10728174]\n",
      " [ 0.08978891  0.10776686  0.09105111  0.09851979  0.09375058  0.09820256\n",
      "   0.10943487  0.111677    0.10090849  0.09889988]\n",
      " [ 0.10287295  0.09615505  0.09798539  0.09449223  0.09873859  0.10509123\n",
      "   0.09380344  0.09523899  0.10227623  0.11334589]\n",
      " [ 0.10275288  0.09191971  0.09495049  0.10340624  0.10730265  0.09686816\n",
      "   0.10082452  0.09418924  0.10006739  0.10771868]\n",
      " [ 0.1016719   0.09480406  0.09609508  0.09996186  0.091249    0.10246729\n",
      "   0.10262737  0.10562931  0.10042007  0.10507398]\n",
      " [ 0.1064569   0.09730442  0.10108738  0.09618084  0.08431156  0.10824071\n",
      "   0.10021188  0.09103455  0.1088098   0.10636194]\n",
      " [ 0.09741698  0.09187383  0.09985817  0.09640195  0.10016352  0.10243624\n",
      "   0.10913292  0.10217617  0.10143054  0.09910964]\n",
      " [ 0.1045827   0.08828956  0.10475232  0.10515241  0.0903369   0.10062205\n",
      "   0.10170785  0.1053348   0.10758117  0.0916402 ]\n",
      " [ 0.10432307  0.09731662  0.11151731  0.08882541  0.0862409   0.10272025\n",
      "   0.09871031  0.09969387  0.10216086  0.10849135]\n",
      " [ 0.09523573  0.10337241  0.09701127  0.09964662  0.09968019  0.10020825\n",
      "   0.09738509  0.10391548  0.102801    0.10074389]\n",
      " [ 0.11718798  0.1045537   0.09855686  0.09863375  0.09249681  0.09910037\n",
      "   0.09484742  0.09835031  0.0987426   0.09753016]\n",
      " [ 0.10464592  0.0905733   0.10212591  0.10065883  0.08689869  0.10485313\n",
      "   0.10390118  0.11383531  0.09457517  0.09793251]\n",
      " [ 0.09636553  0.08883324  0.09932933  0.1029041   0.09823044  0.10813219\n",
      "   0.10467235  0.10260519  0.09543473  0.1034929 ]\n",
      " [ 0.11733595  0.10099906  0.09269281  0.09520229  0.09012371  0.09515204\n",
      "   0.1104233   0.09750462  0.10895313  0.09161317]\n",
      " [ 0.11509058  0.09470635  0.09843411  0.10169037  0.09329628  0.09767329\n",
      "   0.10706828  0.09791676  0.0961922   0.09793184]\n",
      " [ 0.10101455  0.09927502  0.09124086  0.10152167  0.09657045  0.10192195\n",
      "   0.11209525  0.10673744  0.09611068  0.09351214]\n",
      " [ 0.10436305  0.08424764  0.10339738  0.08175862  0.08772496  0.10956915\n",
      "   0.10134906  0.10193214  0.11038463  0.11527341]\n",
      " [ 0.10745683  0.09860628  0.09769125  0.09585948  0.08771788  0.10369392\n",
      "   0.10429382  0.10117207  0.10563453  0.09787394]\n",
      " [ 0.09760286  0.08687469  0.11140594  0.09891085  0.10298595  0.09611489\n",
      "   0.09196262  0.10621227  0.10545006  0.10247991]\n",
      " [ 0.10433799  0.1022219   0.10114686  0.09581501  0.08914989  0.09827233\n",
      "   0.0985573   0.1018811   0.10903221  0.09958545]\n",
      " [ 0.10288177  0.09059437  0.09870764  0.10248421  0.09818836  0.10534715\n",
      "   0.10487947  0.10056619  0.09548493  0.10086588]\n",
      " [ 0.09872085  0.09005385  0.08731472  0.09950344  0.09158583  0.1087746\n",
      "   0.10865101  0.09709245  0.1089338   0.10936932]\n",
      " [ 0.10934366  0.0948944   0.10881658  0.10460144  0.08718484  0.10065617\n",
      "   0.1066835   0.08797652  0.10194595  0.09789694]\n",
      " [ 0.09396731  0.09763757  0.09796353  0.09566627  0.1093678   0.10276386\n",
      "   0.10686553  0.09703182  0.09866722  0.10006905]\n",
      " [ 0.10395288  0.094299    0.11330239  0.10096272  0.08011355  0.10197544\n",
      "   0.09404031  0.09748213  0.11097879  0.10289279]\n",
      " [ 0.11392362  0.09811208  0.10520229  0.09546806  0.09122463  0.10840733\n",
      "   0.0968331   0.09541322  0.1020987   0.09331689]\n",
      " [ 0.10313961  0.09355497  0.09166206  0.09757995  0.09956296  0.10413621\n",
      "   0.11031329  0.0978867   0.10064894  0.1015153 ]\n",
      " [ 0.09781878  0.10519762  0.09770658  0.10140008  0.08964935  0.10820126\n",
      "   0.09538865  0.09929086  0.10497886  0.10036797]\n",
      " [ 0.091708    0.09923428  0.10042109  0.09713002  0.10105545  0.09575332\n",
      "   0.10629718  0.10560578  0.09882264  0.10397223]\n",
      " [ 0.10817856  0.08517061  0.09622903  0.0949068   0.09356632  0.10222568\n",
      "   0.10617623  0.09852137  0.09655114  0.11847421]\n",
      " [ 0.1125812   0.10340168  0.08707339  0.09674811  0.08971917  0.10546742\n",
      "   0.09390122  0.09286802  0.11475671  0.10348311]\n",
      " [ 0.10849571  0.09711514  0.098149    0.09996339  0.08862108  0.10250715\n",
      "   0.09964361  0.09497084  0.10120184  0.10933224]\n",
      " [ 0.09450055  0.09628946  0.09801975  0.09203498  0.08931217  0.10676228\n",
      "   0.12493636  0.09902753  0.10625927  0.09285761]\n",
      " [ 0.10129745  0.11168385  0.10898252  0.09024103  0.09202982  0.10825446\n",
      "   0.10162436  0.0942892   0.10603645  0.08556081]\n",
      " [ 0.09923558  0.09551916  0.09650466  0.09445777  0.09908661  0.10473599\n",
      "   0.1129619   0.09833031  0.10194723  0.0972208 ]\n",
      " [ 0.11909512  0.08651047  0.11256719  0.09482596  0.0853586   0.10634174\n",
      "   0.09375814  0.09313335  0.10804281  0.10036657]\n",
      " [ 0.10343203  0.10228276  0.09775466  0.09959917  0.1022426   0.10256543\n",
      "   0.10140641  0.0941294   0.10377471  0.09281277]\n",
      " [ 0.11555341  0.09332392  0.09570931  0.09032796  0.08846001  0.0989886\n",
      "   0.10808762  0.08776194  0.12236768  0.09941952]\n",
      " [ 0.10497215  0.09862001  0.10251363  0.08575472  0.09948612  0.10515716\n",
      "   0.10237446  0.09785663  0.0999907   0.10327447]\n",
      " [ 0.09399961  0.10401899  0.10162157  0.09874886  0.09622317  0.10263511\n",
      "   0.09948683  0.09813863  0.09717123  0.10795589]\n",
      " [ 0.10435694  0.09410127  0.09456095  0.09809086  0.09347829  0.10433643\n",
      "   0.1164517   0.09625743  0.09790707  0.10045906]\n",
      " [ 0.10128007  0.09430336  0.10219859  0.09580103  0.08890874  0.1025362\n",
      "   0.10877975  0.09721219  0.10422663  0.10475343]\n",
      " [ 0.10039016  0.10054493  0.09113155  0.10452427  0.09676198  0.10028012\n",
      "   0.09849781  0.1101167   0.10131487  0.09643761]\n",
      " [ 0.10549426  0.09777655  0.0941572   0.09615958  0.08830541  0.09793775\n",
      "   0.09868701  0.10266922  0.11536866  0.10344446]\n",
      " [ 0.10787883  0.09287905  0.10215919  0.10000269  0.10107443  0.09899005\n",
      "   0.101877    0.09455485  0.1002841   0.10029978]\n",
      " [ 0.09503426  0.09451885  0.09085634  0.10134498  0.09839676  0.10285675\n",
      "   0.1032934   0.10828584  0.10460403  0.10080889]\n",
      " [ 0.10373288  0.09554321  0.0861236   0.10364951  0.09197893  0.10267769\n",
      "   0.09037446  0.10137714  0.11467541  0.10986713]\n",
      " [ 0.09903966  0.08766763  0.09520473  0.09951014  0.08923572  0.09761525\n",
      "   0.10939968  0.09823091  0.11785618  0.10624011]\n",
      " [ 0.11426782  0.09132076  0.09733864  0.09563597  0.09799932  0.10720459\n",
      "   0.10266718  0.10428156  0.09893642  0.09034775]\n",
      " [ 0.11711463  0.0864445   0.10084005  0.09534309  0.08718699  0.10933219\n",
      "   0.10140598  0.10022222  0.11378541  0.08832506]\n",
      " [ 0.1004129   0.10090777  0.10324609  0.09371503  0.09988695  0.0981452\n",
      "   0.10502255  0.09651437  0.10250247  0.09964667]\n",
      " [ 0.09652661  0.09274288  0.10032688  0.10377237  0.0926239   0.10441381\n",
      "   0.09959348  0.10605597  0.09638729  0.10755685]\n",
      " [ 0.10411412  0.10036537  0.09340825  0.10805508  0.10420261  0.09947061\n",
      "   0.10035121  0.09904908  0.0960455   0.09493814]\n",
      " [ 0.11417645  0.10636079  0.09228281  0.08957566  0.08635359  0.10399968\n",
      "   0.11547974  0.09076672  0.10350993  0.09749459]\n",
      " [ 0.11556189  0.09319758  0.10631085  0.1017862   0.09197313  0.0967386\n",
      "   0.09153259  0.09571749  0.10552967  0.10165197]\n",
      " [ 0.10751569  0.09871115  0.1022872   0.08811149  0.09271446  0.10231105\n",
      "   0.10342178  0.11385049  0.10525237  0.0858243 ]\n",
      " [ 0.10049446  0.10560264  0.10213686  0.08563756  0.09722324  0.10131287\n",
      "   0.10185711  0.10394655  0.10411973  0.09766902]\n",
      " [ 0.09452013  0.09658827  0.09946091  0.10377367  0.09436908  0.09911892\n",
      "   0.10363279  0.10617477  0.10324999  0.09911153]\n",
      " [ 0.09108624  0.09307264  0.091718    0.1055438   0.09592818  0.10584022\n",
      "   0.10917201  0.09579604  0.10070235  0.1111406 ]\n",
      " [ 0.11325488  0.10044537  0.0961783   0.09503125  0.0946335   0.09692257\n",
      "   0.10593724  0.09660695  0.10860715  0.09238268]\n",
      " [ 0.11036617  0.09158078  0.0989301   0.09560119  0.08960311  0.10635043\n",
      "   0.10990441  0.09613521  0.10688404  0.09464459]\n",
      " [ 0.09856568  0.08433041  0.10182887  0.11102413  0.09901097  0.10093519\n",
      "   0.10160475  0.09113467  0.10711991  0.10444549]\n",
      " [ 0.09858285  0.09783808  0.10404575  0.09875338  0.10000648  0.10028873\n",
      "   0.09727222  0.10236109  0.10010747  0.10074398]\n",
      " [ 0.10232922  0.09944278  0.09830924  0.09833915  0.1042947   0.10232716\n",
      "   0.10032395  0.09808706  0.09714575  0.09940102]\n",
      " [ 0.09896658  0.09881891  0.09584538  0.09480678  0.09918941  0.09934286\n",
      "   0.10396042  0.11166555  0.09312857  0.10427552]\n",
      " [ 0.1160624   0.10945743  0.10444002  0.09530977  0.0910816   0.09493072\n",
      "   0.11065695  0.09893796  0.09208114  0.08704207]\n",
      " [ 0.09773997  0.09483021  0.10363865  0.09806369  0.10133898  0.10210245\n",
      "   0.0971279   0.1030983   0.09663168  0.10542817]\n",
      " [ 0.10290499  0.11116516  0.09280673  0.10123946  0.10374119  0.09672548\n",
      "   0.09601387  0.09795032  0.09866714  0.09878578]\n",
      " [ 0.11214815  0.10131614  0.09802528  0.09245561  0.08688109  0.10997816\n",
      "   0.09981044  0.09848485  0.09610844  0.10479181]\n",
      " [ 0.09855261  0.0977442   0.10130388  0.08951963  0.08911011  0.10635734\n",
      "   0.10399949  0.11130483  0.10707776  0.09503019]\n",
      " [ 0.10699196  0.09189752  0.10686309  0.11025651  0.08700154  0.10146856\n",
      "   0.09533907  0.09084494  0.10898611  0.10035069]\n",
      " [ 0.10473192  0.09611703  0.09608501  0.09891675  0.09026285  0.10352792\n",
      "   0.10032245  0.10034287  0.10768864  0.10200448]\n",
      " [ 0.09901582  0.09915534  0.0987412   0.10318785  0.08458898  0.11282134\n",
      "   0.09785577  0.09210243  0.10427866  0.10825259]\n",
      " [ 0.11718926  0.09326927  0.09946629  0.09666705  0.09225186  0.09349668\n",
      "   0.09153163  0.1097161   0.10670131  0.09971046]\n",
      " [ 0.10430468  0.09717902  0.09493062  0.10334723  0.09974422  0.08997571\n",
      "   0.10261553  0.09947735  0.10088563  0.10754005]\n",
      " [ 0.10638293  0.09887904  0.10574473  0.09703398  0.08660426  0.09828392\n",
      "   0.09861226  0.10479354  0.10782883  0.09583655]\n",
      " [ 0.1119373   0.092283    0.10024384  0.09550612  0.10293213  0.10052487\n",
      "   0.09572262  0.10147361  0.1041159   0.09526058]] (18.414 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.7902\n",
      "INFO:tensorflow:probabilities = [[ 0.10018022  0.10226602  0.09060315  0.09592437  0.09642281  0.10021652\n",
      "   0.11409381  0.09611925  0.10724393  0.09692996]\n",
      " [ 0.10909712  0.09542955  0.10511538  0.09055287  0.0906411   0.100904\n",
      "   0.10594088  0.10338895  0.09397562  0.10495459]\n",
      " [ 0.09353853  0.10988117  0.0996525   0.08956128  0.09505031  0.09927814\n",
      "   0.09780557  0.10993302  0.10581195  0.09948749]\n",
      " [ 0.10088168  0.09171896  0.09496715  0.10267548  0.09943204  0.10028818\n",
      "   0.10962309  0.10064614  0.09850559  0.10126177]\n",
      " [ 0.10629699  0.09404378  0.10849509  0.09235547  0.09175079  0.09733788\n",
      "   0.09732612  0.09375259  0.10773449  0.11090678]\n",
      " [ 0.1092691   0.10204195  0.10102868  0.09154666  0.09450286  0.10881032\n",
      "   0.10662305  0.09787216  0.1024154   0.08588983]\n",
      " [ 0.10945553  0.10088772  0.09825918  0.09939624  0.0967019   0.10112688\n",
      "   0.09711298  0.09582221  0.10342022  0.09781718]\n",
      " [ 0.10682119  0.08924584  0.09063146  0.10629556  0.08810172  0.11613902\n",
      "   0.10423176  0.09556685  0.10203633  0.10093024]\n",
      " [ 0.09966111  0.10660581  0.09513728  0.10251717  0.08765739  0.10375776\n",
      "   0.10098752  0.10940748  0.09039361  0.10387491]\n",
      " [ 0.11115752  0.08975605  0.09825789  0.09550202  0.08585309  0.11725422\n",
      "   0.10292169  0.09659563  0.09670932  0.10599259]\n",
      " [ 0.10149059  0.09620993  0.09259719  0.0966066   0.10150304  0.10373461\n",
      "   0.10057415  0.10899974  0.09777474  0.10050947]\n",
      " [ 0.10300329  0.08765741  0.09426095  0.09804326  0.0951945   0.10037873\n",
      "   0.11932154  0.09839919  0.10371159  0.1000296 ]\n",
      " [ 0.10458964  0.0880394   0.09676385  0.10028146  0.09579092  0.09854087\n",
      "   0.09960496  0.09246448  0.11014359  0.11378084]\n",
      " [ 0.10044092  0.10069881  0.0956299   0.09335601  0.10227379  0.10032058\n",
      "   0.09620343  0.10060006  0.0975342   0.11294237]\n",
      " [ 0.10171591  0.0971583   0.09795581  0.09632758  0.09029766  0.10208568\n",
      "   0.10174408  0.09617006  0.11569406  0.10085084]\n",
      " [ 0.12862752  0.09441666  0.09363819  0.10358183  0.08679298  0.09850017\n",
      "   0.10497622  0.09496304  0.10325607  0.09124736]\n",
      " [ 0.0941214   0.10365339  0.09610738  0.10257602  0.10242556  0.09930978\n",
      "   0.09853451  0.10028408  0.10102872  0.10195915]\n",
      " [ 0.11144777  0.09348012  0.09355118  0.10093819  0.09308108  0.10287552\n",
      "   0.10357764  0.09892191  0.10081558  0.10131094]\n",
      " [ 0.10252978  0.10982916  0.09745843  0.1066986   0.09538772  0.10310608\n",
      "   0.09190579  0.10229351  0.10175323  0.0890377 ]\n",
      " [ 0.10639606  0.09239912  0.10024946  0.0983955   0.08762333  0.105037\n",
      "   0.09538426  0.10889208  0.10241536  0.10320785]\n",
      " [ 0.10212811  0.10674101  0.09455926  0.09800912  0.0938468   0.09995794\n",
      "   0.09955897  0.10319734  0.09836761  0.10363381]\n",
      " [ 0.1100911   0.08676841  0.09068348  0.10192149  0.10002132  0.1067631\n",
      "   0.09476098  0.09868388  0.10281737  0.10748883]\n",
      " [ 0.09560984  0.10822986  0.09561992  0.09908932  0.09226433  0.10926632\n",
      "   0.09540374  0.10269497  0.10207058  0.09975109]\n",
      " [ 0.10233605  0.08741363  0.08557917  0.10148161  0.09207334  0.10946088\n",
      "   0.10765214  0.11145715  0.09692353  0.10562254]\n",
      " [ 0.10243484  0.09611318  0.09225774  0.09150627  0.10806061  0.10318425\n",
      "   0.10566613  0.10571689  0.09455185  0.10050829]\n",
      " [ 0.1007422   0.10059096  0.10182586  0.09329261  0.09073626  0.09989275\n",
      "   0.10972603  0.09933956  0.10588656  0.09796731]\n",
      " [ 0.12037697  0.10330186  0.10152406  0.099043    0.09263308  0.09460138\n",
      "   0.10197996  0.08605759  0.09163152  0.10885051]\n",
      " [ 0.10419273  0.09238093  0.10444825  0.10337321  0.08963174  0.10890191\n",
      "   0.10672915  0.09691378  0.09534171  0.09808654]\n",
      " [ 0.11264239  0.09975848  0.0957851   0.10077737  0.09844786  0.10006765\n",
      "   0.08818472  0.10721238  0.09956578  0.09755828]\n",
      " [ 0.10191198  0.10216111  0.10246438  0.10893819  0.10005194  0.09059599\n",
      "   0.09494779  0.09696975  0.10563343  0.09632547]\n",
      " [ 0.09927665  0.10386468  0.09710305  0.09601593  0.08722928  0.10688179\n",
      "   0.11022124  0.10232734  0.09816918  0.09891091]\n",
      " [ 0.10577114  0.09533699  0.09967635  0.08761214  0.08888199  0.10702944\n",
      "   0.10496738  0.10579796  0.09751192  0.10741467]\n",
      " [ 0.10577346  0.10410683  0.08722176  0.0828691   0.08802793  0.10802608\n",
      "   0.10592089  0.10882476  0.10152204  0.10770712]\n",
      " [ 0.09759804  0.09926266  0.10834203  0.09313791  0.09340221  0.09620856\n",
      "   0.10465395  0.10495016  0.09995081  0.10249363]\n",
      " [ 0.0908713   0.10649391  0.0859353   0.0972824   0.0938897   0.10767827\n",
      "   0.104623    0.10671393  0.10692442  0.0995877 ]\n",
      " [ 0.10691226  0.08565663  0.09937398  0.09298234  0.10057096  0.11584702\n",
      "   0.104856    0.09447866  0.1019692   0.09735286]\n",
      " [ 0.09469493  0.11166143  0.08845804  0.10250929  0.09048606  0.09909219\n",
      "   0.10594965  0.10160991  0.10841551  0.097123  ]\n",
      " [ 0.1016449   0.09477321  0.09953111  0.0952796   0.08849795  0.11155247\n",
      "   0.10332949  0.09487525  0.10657689  0.10393917]\n",
      " [ 0.10273328  0.09995168  0.09897347  0.10319522  0.09550715  0.09786124\n",
      "   0.1082001   0.09751383  0.10116193  0.0949022 ]\n",
      " [ 0.10688065  0.09366132  0.10380685  0.09529309  0.09533285  0.10128205\n",
      "   0.09352066  0.0987828   0.10246179  0.10897796]\n",
      " [ 0.1050778   0.09638368  0.0929284   0.09724937  0.09160683  0.10568611\n",
      "   0.101601    0.10650702  0.10687862  0.09608116]\n",
      " [ 0.10956708  0.09121263  0.10203668  0.09715782  0.08903234  0.10387956\n",
      "   0.10549048  0.0979875   0.10728945  0.09634651]\n",
      " [ 0.09328586  0.10853069  0.0951476   0.10815575  0.09624493  0.09576786\n",
      "   0.09745094  0.10015466  0.1089468   0.09631502]\n",
      " [ 0.10433375  0.09150086  0.10199003  0.09746668  0.10441817  0.0969684\n",
      "   0.10100801  0.10119583  0.10219715  0.09892107]\n",
      " [ 0.10022612  0.10552704  0.11147977  0.09472624  0.09233917  0.09651713\n",
      "   0.10327861  0.09479401  0.10286716  0.0982447 ]\n",
      " [ 0.11265567  0.09088313  0.09969427  0.09855272  0.10034158  0.10523416\n",
      "   0.10515094  0.08418179  0.09911045  0.10419524]\n",
      " [ 0.09864492  0.07873836  0.10881077  0.10889353  0.10683665  0.09596878\n",
      "   0.10609114  0.0951338   0.10761612  0.0932659 ]\n",
      " [ 0.1094031   0.10405827  0.09061292  0.09330039  0.08918707  0.10243098\n",
      "   0.1030765   0.09967964  0.11053155  0.09771959]\n",
      " [ 0.10936891  0.10133172  0.10541424  0.09839289  0.10067105  0.09649698\n",
      "   0.09945253  0.09627153  0.09366175  0.09893833]\n",
      " [ 0.10794409  0.09923046  0.09307126  0.08854803  0.09082627  0.09961493\n",
      "   0.11238858  0.09965467  0.10522499  0.10349678]\n",
      " [ 0.10237969  0.09517445  0.10076345  0.09230348  0.08777782  0.10882837\n",
      "   0.10337108  0.10873438  0.10138901  0.09927823]\n",
      " [ 0.10527381  0.10168804  0.0949292   0.10216755  0.10260394  0.10100936\n",
      "   0.10099254  0.09591912  0.10295632  0.09246019]\n",
      " [ 0.10173416  0.09859194  0.10592867  0.10536934  0.09700137  0.09551354\n",
      "   0.09910823  0.09279129  0.10870907  0.09525245]\n",
      " [ 0.09543804  0.09402566  0.09628721  0.09408996  0.09204425  0.11146998\n",
      "   0.1018417   0.10537916  0.10238676  0.10703726]\n",
      " [ 0.1011953   0.09681751  0.09947666  0.09872829  0.09519903  0.09916924\n",
      "   0.1021915   0.10555528  0.09715736  0.10450986]\n",
      " [ 0.10378863  0.10363951  0.09979888  0.0975394   0.09593113  0.10361385\n",
      "   0.09740183  0.09247979  0.10634071  0.09946627]\n",
      " [ 0.10351175  0.08548092  0.0832147   0.10447329  0.086389    0.10924052\n",
      "   0.1146706   0.09448908  0.11600009  0.10253005]\n",
      " [ 0.10549816  0.09210627  0.10439144  0.10092482  0.09864402  0.10739398\n",
      "   0.09891052  0.09377692  0.09976657  0.09858739]\n",
      " [ 0.11023062  0.09494574  0.09877884  0.09154518  0.08595815  0.09450517\n",
      "   0.10731018  0.10602938  0.10693305  0.10376375]\n",
      " [ 0.09322961  0.0937652   0.0913213   0.09784959  0.09656693  0.11104637\n",
      "   0.10396918  0.10601509  0.10863336  0.09760331]\n",
      " [ 0.10702565  0.10401385  0.09550785  0.09607634  0.09557445  0.0956113\n",
      "   0.09797648  0.10748154  0.10658498  0.09414762]\n",
      " [ 0.10040592  0.10029802  0.10070995  0.09575797  0.08821421  0.1044076\n",
      "   0.09222515  0.09609541  0.10302895  0.11885685]\n",
      " [ 0.08803924  0.09339994  0.09400268  0.09810154  0.09042876  0.09092012\n",
      "   0.11000868  0.11924621  0.11166955  0.10418331]\n",
      " [ 0.0969421   0.09391491  0.10243465  0.10448348  0.08906803  0.08917608\n",
      "   0.10457449  0.10981926  0.11261803  0.09696896]\n",
      " [ 0.1177536   0.0994071   0.09421504  0.08398183  0.09579427  0.10569692\n",
      "   0.10087141  0.09246203  0.10497404  0.10484374]\n",
      " [ 0.1056082   0.09402385  0.10182835  0.09728217  0.10050395  0.09708115\n",
      "   0.1138769   0.09700671  0.08997197  0.10281666]\n",
      " [ 0.09971484  0.09574513  0.09568561  0.11516286  0.08906078  0.1047238\n",
      "   0.10701284  0.09137709  0.10597102  0.09554601]\n",
      " [ 0.10170294  0.10274117  0.09898007  0.09804593  0.09520464  0.10129341\n",
      "   0.10298286  0.09310623  0.10608057  0.09986221]\n",
      " [ 0.10100438  0.09026349  0.10929406  0.10093068  0.09585897  0.10215264\n",
      "   0.09699693  0.09900177  0.099239    0.10525806]\n",
      " [ 0.10332666  0.09263337  0.089632    0.09455765  0.10055775  0.10075402\n",
      "   0.10320973  0.08251483  0.11883319  0.11398082]\n",
      " [ 0.1117851   0.10166372  0.09457649  0.10048271  0.09435907  0.09806918\n",
      "   0.10037283  0.10309894  0.10235448  0.0932375 ]\n",
      " [ 0.10523173  0.08649613  0.1019267   0.10085796  0.10718811  0.09653995\n",
      "   0.10227167  0.09757505  0.0995831   0.1023296 ]\n",
      " [ 0.09808246  0.10638181  0.09811826  0.11188093  0.08741402  0.10168429\n",
      "   0.09932864  0.10163803  0.09898951  0.09648205]\n",
      " [ 0.1078627   0.11100874  0.09799766  0.09993961  0.08756563  0.10606299\n",
      "   0.09818777  0.09217972  0.10497461  0.09422062]\n",
      " [ 0.10112771  0.09731722  0.10404737  0.09183811  0.08591652  0.11231916\n",
      "   0.10397569  0.10209092  0.10595158  0.09541571]\n",
      " [ 0.09217978  0.0786739   0.10688864  0.09073815  0.09975129  0.10053135\n",
      "   0.10173046  0.10459296  0.10940871  0.11550473]\n",
      " [ 0.10739953  0.09364865  0.10394634  0.09433159  0.09114648  0.10271569\n",
      "   0.10433784  0.0959722   0.10017296  0.10632867]\n",
      " [ 0.09305274  0.08484791  0.09989505  0.08993889  0.09566449  0.10575312\n",
      "   0.10506402  0.10647182  0.10890641  0.11040557]\n",
      " [ 0.09487618  0.10366763  0.1019337   0.10309903  0.09655759  0.10004492\n",
      "   0.10782515  0.09324495  0.10379957  0.09495138]\n",
      " [ 0.10079799  0.09461565  0.10506709  0.11337514  0.09189475  0.09564548\n",
      "   0.10661424  0.09348737  0.10249726  0.09600507]\n",
      " [ 0.10332356  0.09011984  0.10524406  0.1019242   0.10139776  0.09002049\n",
      "   0.09941998  0.10679145  0.10436164  0.09739699]\n",
      " [ 0.10471798  0.09820519  0.08338782  0.10350225  0.0964999   0.10841972\n",
      "   0.10744943  0.10493378  0.09127587  0.10160802]\n",
      " [ 0.1180151   0.10009215  0.09709856  0.09616066  0.09803677  0.1061788\n",
      "   0.10254078  0.092254    0.09736705  0.0922562 ]\n",
      " [ 0.10118943  0.08985867  0.10187271  0.0948429   0.09562591  0.1039831\n",
      "   0.098247    0.1004872   0.10632077  0.10757232]\n",
      " [ 0.09906088  0.09646632  0.10182614  0.10835727  0.09616903  0.08610669\n",
      "   0.0949195   0.10786545  0.09950403  0.10972472]\n",
      " [ 0.09872143  0.10038067  0.09697678  0.10495119  0.0955596   0.10118468\n",
      "   0.09364514  0.10698865  0.0961943   0.1053976 ]\n",
      " [ 0.09447759  0.09314288  0.1019441   0.106942    0.08884953  0.09815553\n",
      "   0.09826181  0.09245118  0.10924357  0.1165318 ]\n",
      " [ 0.10134652  0.10154251  0.09346473  0.08929204  0.10339739  0.10707868\n",
      "   0.10595626  0.10031857  0.09999799  0.09760528]\n",
      " [ 0.10790048  0.09295819  0.09062195  0.10055543  0.09673023  0.10055137\n",
      "   0.09997147  0.10565138  0.09792406  0.10713539]\n",
      " [ 0.10708997  0.09179077  0.0865256   0.0936329   0.09264696  0.11983163\n",
      "   0.09714933  0.09766115  0.10243827  0.11123336]\n",
      " [ 0.11665246  0.09117868  0.10296623  0.0851904   0.09376534  0.11371408\n",
      "   0.10533205  0.09490581  0.09963638  0.09665863]\n",
      " [ 0.10510984  0.09754098  0.09418665  0.09029121  0.09096237  0.10504955\n",
      "   0.10812535  0.11206707  0.10002112  0.09664587]\n",
      " [ 0.10461773  0.10511894  0.09656055  0.10206367  0.08744968  0.10599756\n",
      "   0.11377449  0.09529506  0.09561913  0.0935032 ]\n",
      " [ 0.11693495  0.09026839  0.10877216  0.10075256  0.09183343  0.11136045\n",
      "   0.10126942  0.10119144  0.08881857  0.0887986 ]\n",
      " [ 0.10671546  0.09722959  0.09728684  0.09639116  0.09074244  0.10315865\n",
      "   0.10356183  0.09760009  0.10878948  0.09852446]\n",
      " [ 0.10459629  0.09317622  0.10611379  0.08871066  0.11049744  0.09854689\n",
      "   0.09752609  0.10526295  0.09367599  0.10189371]\n",
      " [ 0.10084856  0.09385861  0.09882922  0.098384    0.08776027  0.11635964\n",
      "   0.10251499  0.09658075  0.1086187   0.09624521]\n",
      " [ 0.10374519  0.08063649  0.09102897  0.09016062  0.1041992   0.10185187\n",
      "   0.10575459  0.09797897  0.1073755   0.11726864]\n",
      " [ 0.11002341  0.09951032  0.10201862  0.09937935  0.08406029  0.10007536\n",
      "   0.09549994  0.10543282  0.11060669  0.09339323]\n",
      " [ 0.11386041  0.09500367  0.11205356  0.08986063  0.10594065  0.11229543\n",
      "   0.08690344  0.08206273  0.09955317  0.10246626]] (17.425 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.27751, step = 201 (35.837 sec)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-26878d879345>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/platform/app.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, argv)\u001b[0m\n\u001b[1;32m    122\u001b[0m   \u001b[0;31m# Call the main function, passing through any arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m   \u001b[0;31m# to the final program.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m   \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-26878d879345>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(unused_argv)\u001b[0m\n\u001b[1;32m    129\u001b[0m       \u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_input_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m       \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m       hooks=[logging_hook])\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;31m# Evaluate the model and print results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m    813\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 815\u001b[0;31m           \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    816\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    537\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1011\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1014\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1087\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1090\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m       \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1159\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 941\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    942\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_with_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "\n",
    "def cnn_model_fn(features, labels, mode):\n",
    "    \"\"\"Model function for CNN.\"\"\"\n",
    "    # Input Layer\n",
    "    # Reshape X to 4-D tensor: [batch_size, width, height, channels]\n",
    "    # MNIST images are 28x28 pixels, and have one color channel\n",
    "    input_layer = tf.reshape(features[\"x\"], [-1, 128, 28, 1])\n",
    "\n",
    "    # Convolutional Layer #1\n",
    "    # Computes 32 features using a 5x5 filter with ReLU activation.\n",
    "    # Padding is added to preserve width and height.\n",
    "    # Input Tensor Shape: [batch_size, 28, 28, 1]\n",
    "    # Output Tensor Shape: [batch_size, 28, 28, 32]\n",
    "    conv1 = tf.layers.conv2d(\n",
    "      inputs=input_layer,\n",
    "      filters=32,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "    # Pooling Layer #1\n",
    "    # First max pooling layer with a 2x2 filter and stride of 2\n",
    "    # Input Tensor Shape: [batch_size, 28, 28, 32]\n",
    "    # Output Tensor Shape: [batch_size, 14, 14, 32]\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    # Convolutional Layer #2\n",
    "    # Computes 64 features using a 5x5 filter.\n",
    "    # Padding is added to preserve width and height.\n",
    "    # Input Tensor Shape: [batch_size, 14, 14, 32]\n",
    "    # Output Tensor Shape: [batch_size, 14, 14, 64]\n",
    "    conv2 = tf.layers.conv2d(\n",
    "      inputs=pool1,\n",
    "      filters=64,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "    # Pooling Layer #2\n",
    "    # Second max pooling layer with a 2x2 filter and stride of 2\n",
    "    # Input Tensor Shape: [batch_size, 14, 14, 64]\n",
    "    # Output Tensor Shape: [batch_size, 7, 7, 64]\n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    # Flatten tensor into a batch of vectors\n",
    "    # Input Tensor Shape: [batch_size, 7, 7, 64]\n",
    "    # Output Tensor Shape: [batch_size, 7 * 7 * 64]\n",
    "    pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "\n",
    "    # Dense Layer\n",
    "    # Densely connected layer with 1024 neurons\n",
    "    # Input Tensor Shape: [batch_size, 7 * 7 * 64]\n",
    "    # Output Tensor Shape: [batch_size, 1024]\n",
    "    dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "\n",
    "    # Add dropout operation; 0.6 probability that element will be kept\n",
    "    dropout = tf.layers.dropout(\n",
    "      inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "    # Logits layer\n",
    "    # Input Tensor Shape: [batch_size, 1024]\n",
    "    # Output Tensor Shape: [batch_size, 10]\n",
    "    logits = tf.layers.dense(inputs=dropout, units=10)\n",
    "\n",
    "    predictions = {\n",
    "      # Generate predictions (for PREDICT and EVAL mode)\n",
    "      \"classes\": tf.argmax(input=logits, axis=1),\n",
    "      # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "      # `logging_hook`.\n",
    "      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "    }\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "    # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "\n",
    "    # Configure the Training Op (for TRAIN mode)\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "  # Add evaluation metrics (for EVAL mode)\n",
    "    eval_metric_ops = {\n",
    "      \"accuracy\": tf.metrics.accuracy(\n",
    "          labels=labels, predictions=predictions[\"classes\"])}\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n",
    "\n",
    "\n",
    "def main(unused_argv):\n",
    "    # Load training and eval data\n",
    "    mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n",
    "    train_data = mnist.train.images  # Returns np.array\n",
    "    train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n",
    "    eval_data = mnist.test.images  # Returns np.array\n",
    "    eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)\n",
    "\n",
    "    # Create the Estimator\n",
    "    mnist_classifier = tf.estimator.Estimator(\n",
    "      model_fn=cnn_model_fn, model_dir=\"/tmp/mnist_convnet_model\")\n",
    "\n",
    "    # Set up logging for predictions\n",
    "    # Log the values in the \"Softmax\" tensor with label \"probabilities\"\n",
    "    tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "    logging_hook = tf.train.LoggingTensorHook(\n",
    "      tensors=tensors_to_log, every_n_iter=50)\n",
    "\n",
    "    # Train the model\n",
    "    train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x={\"x\": train_data},\n",
    "      y=train_labels,\n",
    "      batch_size=100,\n",
    "      num_epochs=None,\n",
    "      shuffle=True)\n",
    "    mnist_classifier.train(\n",
    "      input_fn=train_input_fn,\n",
    "      steps=20000,\n",
    "      hooks=[logging_hook])\n",
    "\n",
    "    # Evaluate the model and print results\n",
    "    eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x={\"x\": eval_data},\n",
    "      y=eval_labels,\n",
    "      num_epochs=1,\n",
    "      shuffle=False)\n",
    "    eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n",
    "    print(eval_results)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
